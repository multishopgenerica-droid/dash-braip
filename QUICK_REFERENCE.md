# ğŸš€ Quick Reference - v8.1 Mega

> Guia rÃ¡pido de comandos e referÃªncias

## CLI & Make

```bash
# Desenvolvimento
make dev              # Inicia dev server
make test             # Roda testes
make lint             # Roda linter
make format           # Formata cÃ³digo

# Ou via CLI
./cli.sh dev
./cli.sh test
./cli.sh db:migrate
```

## Docker

```bash
make docker-up        # Sobe containers
make docker-down      # Para containers
make docker-logs      # Ver logs
./cli.sh shell app    # Shell no container
```

## Database

```bash
./cli.sh db:migrate        # Migration segura (com backup)
./cli.sh db:rollback       # Rollback
./cli.sh db:backup         # Backup manual
./scripts/db/safe-migrate.sh  # Migration completa
```

## Deploy

```bash
./cli.sh deploy:staging      # Deploy staging
./cli.sh deploy:production   # Deploy prod (com confirmaÃ§Ã£o)
./cli.sh rollback            # Rollback emergÃªncia

# AvanÃ§ado
./scripts/canary-deploy.sh v1.2.3      # Canary deployment
./scripts/blue-green-deploy.sh v1.2.3  # Blue-green
```

## Monitoramento


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸš€ v8.0 ULTIMATE EDITION - A ESTRUTURA DEFINITIVA
#
#   Inclui TUDO:
#   - v7.1: Testing Complete (E2E, Contract, Visual, Mutation)
#   - v7.2: Observability Complete (Dashboards, SLOs, Alerting)  
#   - v8.0: Infrastructure as Code (Terraform, K8s, GitOps)
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${PURPLE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${PURPLE}  ğŸš€ v8.0 ULTIMATE EDITION - CRIANDO ESTRUTURA DEFINITIVA                    ${NC}"
echo -e "${PURPLE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Criar todos os diretÃ³rios
mkdir -p tests/{e2e/{fixtures,pages,specs},contract/{consumer,provider},visual,smoke,factories,mocks,integration,unit}
mkdir -p monitoring/{grafana/{dashboards,provisioning/{datasources,dashboards}},prometheus/rules,alertmanager}
mkdir -p infrastructure/{terraform/{modules/{vpc,eks,rds,redis,s3},environments/{dev,staging,prod}},kubernetes/{base,overlays/{dev,staging,prod}},helm}
mkdir -p docs/{slo,api,architecture}
mkdir -p .github/workflows

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸ§ª PARTE 1: v7.1 TESTING COMPLETE
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸ§ª PARTE 1: v7.1 TESTING COMPLETE                                          â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 91: playwright.config.ts - E2E Testing
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [91/150] playwright.config.ts${NC}"

cat > playwright.config.ts << 'EOFPLAYWRIGHT'
import { defineConfig, devices } from '@playwright/test';

export default defineConfig({
  testDir: './tests/e2e/specs',
  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  reporter: [
    ['html', { outputFolder: 'reports/playwright' }],
    ['json', { outputFile: 'reports/playwright/results.json' }],
    ['junit', { outputFile: 'reports/playwright/junit.xml' }],
    process.env.CI ? ['github'] : ['list'],
  ],
  
  use: {
    baseURL: process.env.BASE_URL || 'http://localhost:3000',
    trace: 'on-first-retry',
    screenshot: 'only-on-failure',
    video: 'retain-on-failure',
  },

  projects: [
    { name: 'setup', testMatch: /.*\.setup\.ts/ },
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'], storageState: 'tests/e2e/.auth/user.json' },
      dependencies: ['setup'],
    },
    {
      name: 'firefox',
      use: { ...devices['Desktop Firefox'], storageState: 'tests/e2e/.auth/user.json' },
      dependencies: ['setup'],
    },
    {
      name: 'webkit',
      use: { ...devices['Desktop Safari'], storageState: 'tests/e2e/.auth/user.json' },
      dependencies: ['setup'],
    },
    {
      name: 'mobile-chrome',
      use: { ...devices['Pixel 5'], storageState: 'tests/e2e/.auth/user.json' },
      dependencies: ['setup'],
    },
    {
      name: 'mobile-safari',
      use: { ...devices['iPhone 13'], storageState: 'tests/e2e/.auth/user.json' },
      dependencies: ['setup'],
    },
  ],

  webServer: process.env.CI ? undefined : {
    command: 'npm run dev',
    url: 'http://localhost:3000',
    reuseExistingServer: !process.env.CI,
  },
});
EOFPLAYWRIGHT

echo -e "${GREEN}   âœ… playwright.config.ts${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 92: tests/e2e/pages/BasePage.ts
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [92/150] tests/e2e/pages/BasePage.ts${NC}"

cat > tests/e2e/pages/BasePage.ts << 'EOFBASEPAGE'
import { Page, Locator, expect } from '@playwright/test';

export abstract class BasePage {
  readonly page: Page;
  abstract readonly path: string;

  constructor(page: Page) { this.page = page; }

  async goto() {
    await this.page.goto(this.path);
    await this.page.waitForLoadState('domcontentloaded');
  }

  get loading(): Locator { return this.page.locator('[data-testid="loading"]'); }
  get toast(): Locator { return this.page.locator('[data-testid="toast"]'); }
  get errorMessage(): Locator { return this.page.locator('[data-testid="error-message"]'); }

  async waitForLoading() {
    await this.loading.waitFor({ state: 'visible', timeout: 5000 }).catch(() => {});
    await this.loading.waitFor({ state: 'hidden', timeout: 30000 });
  }

  async getByTestId(testId: string): Promise<Locator> {
    return this.page.locator(`[data-testid="${testId}"]`);
  }

  async fillField(testId: string, value: string) {
    const field = await this.getByTestId(testId);
    await field.clear();
    await field.fill(value);
  }

  async clickButton(testId: string) {
    await (await this.getByTestId(testId)).click();
  }

  async expectVisible(testId: string) {
    await expect(await this.getByTestId(testId)).toBeVisible();
  }

  async expectText(testId: string, text: string | RegExp) {
    await expect(await this.getByTestId(testId)).toHaveText(text);
  }

  async takeScreenshot(name: string) {
    await this.page.screenshot({ path: `reports/screenshots/${name}.png`, fullPage: true });
  }
}
EOFBASEPAGE

echo -e "${GREEN}   âœ… tests/e2e/pages/BasePage.ts${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 93: tests/e2e/pages/LoginPage.ts
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [93/150] tests/e2e/pages/LoginPage.ts${NC}"

cat > tests/e2e/pages/LoginPage.ts << 'EOFLOGINPAGE'
import { Locator, expect } from '@playwright/test';
import { BasePage } from './BasePage';

export class LoginPage extends BasePage {
  readonly path = '/login';

  get emailInput(): Locator { return this.page.locator('[data-testid="email"]'); }
  get passwordInput(): Locator { return this.page.locator('[data-testid="password"]'); }
  get loginButton(): Locator { return this.page.locator('[data-testid="login-button"]'); }
  get forgotPasswordLink(): Locator { return this.page.locator('[data-testid="forgot-password"]'); }

  async login(email: string, password: string) {
    await this.emailInput.fill(email);
    await this.passwordInput.fill(password);
    await this.loginButton.click();
  }

  async loginAndExpectSuccess(email: string, password: string) {
    await this.login(email, password);
    await this.page.waitForURL('**/dashboard**');
    await expect(this.page).toHaveURL(/dashboard/);
  }

  async loginAndExpectError(email: string, password: string, expectedError?: string) {
    await this.login(email, password);
    await expect(this.errorMessage).toBeVisible();
    if (expectedError) await expect(this.errorMessage).toContainText(expectedError);
  }
}
EOFLOGINPAGE

echo -e "${GREEN}   âœ… tests/e2e/pages/LoginPage.ts${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 94: tests/e2e/specs/auth.spec.ts
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [94/150] tests/e2e/specs/auth.spec.ts${NC}"

cat > tests/e2e/specs/auth.spec.ts << 'EOFAUTHSPEC'
import { test, expect } from '@playwright/test';
import { LoginPage } from '../pages/LoginPage';

test.describe('Authentication', () => {
  let loginPage: LoginPage;

  test.beforeEach(async ({ page }) => {
    loginPage = new LoginPage(page);
    await loginPage.goto();
  });

  test('should login successfully with valid credentials', async () => {
    await loginPage.loginAndExpectSuccess(
      process.env.TEST_USER_EMAIL || 'test@example.com',
      process.env.TEST_USER_PASSWORD || 'Test123!@#'
    );
  });

  test('should show error with invalid credentials', async () => {
    await loginPage.loginAndExpectError('invalid@example.com', 'wrongpassword', 'Credenciais invÃ¡lidas');
  });

  test('should show error for empty email', async () => {
    await loginPage.passwordInput.fill('somepassword');
    await loginPage.loginButton.click();
    await expect(loginPage.emailInput).toHaveAttribute('aria-invalid', 'true');
  });

  test('should redirect to dashboard after login', async ({ page }) => {
    await loginPage.login(
      process.env.TEST_USER_EMAIL || 'test@example.com',
      process.env.TEST_USER_PASSWORD || 'Test123!@#'
    );
    await expect(page).toHaveURL(/dashboard/);
  });
});
EOFAUTHSPEC

echo -e "${GREEN}   âœ… tests/e2e/specs/auth.spec.ts${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 95: tests/factories/index.ts - Test Data Factories
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [95/150] tests/factories/index.ts${NC}"

cat > tests/factories/index.ts << 'EOFFACTORIES'
import { faker } from '@faker-js/faker';

// Types
export interface User {
  id: string; email: string; name: string; role: 'admin' | 'manager' | 'user';
  createdAt: Date; updatedAt: Date;
}

export interface Product {
  id: string; name: string; description: string; price: number;
  category: string; stock: number; active: boolean; createdAt: Date;
}

export interface Order {
  id: string; userId: string; items: OrderItem[]; total: number;
  status: 'pending' | 'processing' | 'shipped' | 'delivered' | 'cancelled'; createdAt: Date;
}

export interface OrderItem { productId: string; quantity: number; price: number; }

// Factory Class
class Factory<T> {
  private defaults: () => T;
  constructor(defaults: () => T) { this.defaults = defaults; }
  build(overrides: Partial<T> = {}): T { return { ...this.defaults(), ...overrides }; }
  buildList(count: number, overrides: Partial<T> = {}): T[] {
    return Array.from({ length: count }, () => this.build(overrides));
  }
}

// Factories
export const userFactory = new Factory<User>(() => ({
  id: faker.string.uuid(),
  email: faker.internet.email(),
  name: faker.person.fullName(),
  role: faker.helpers.arrayElement(['admin', 'manager', 'user']),
  createdAt: faker.date.past(),
  updatedAt: faker.date.recent(),
}));

export const productFactory = new Factory<Product>(() => ({
  id: faker.string.uuid(),
  name: faker.commerce.productName(),
  description: faker.commerce.productDescription(),
  price: parseFloat(faker.commerce.price({ min: 10, max: 1000 })),
  category: faker.commerce.department(),
  stock: faker.number.int({ min: 0, max: 100 }),
  active: faker.datatype.boolean({ probability: 0.9 }),
  createdAt: faker.date.past(),
}));

export const orderItemFactory = new Factory<OrderItem>(() => ({
  productId: faker.string.uuid(),
  quantity: faker.number.int({ min: 1, max: 5 }),
  price: parseFloat(faker.commerce.price({ min: 10, max: 500 })),
}));

export const orderFactory = new Factory<Order>(() => {
  const items = orderItemFactory.buildList(faker.number.int({ min: 1, max: 5 }));
  return {
    id: faker.string.uuid(),
    userId: faker.string.uuid(),
    items,
    total: items.reduce((sum, item) => sum + item.price * item.quantity, 0),
    status: faker.helpers.arrayElement(['pending', 'processing', 'shipped', 'delivered', 'cancelled']),
    createdAt: faker.date.past(),
  };
});

// Specialized Builders
export const builders = {
  adminUser: () => userFactory.build({ role: 'admin' }),
  regularUser: () => userFactory.build({ role: 'user' }),
  activeProduct: () => productFactory.build({ active: true, stock: 50 }),
  outOfStockProduct: () => productFactory.build({ active: true, stock: 0 }),
  pendingOrder: () => orderFactory.build({ status: 'pending' }),
  completedOrder: () => orderFactory.build({ status: 'delivered' }),
};

// Helpers
export const generateRandomEmail = () => `test_${Date.now()}_${Math.random().toString(36).substring(7)}@example.com`;
export const generateRandomCPF = () => {
  const r = () => Math.floor(Math.random() * 9);
  return `${r()}${r()}${r()}.${r()}${r()}${r()}.${r()}${r()}${r()}-${r()}${r()}`;
};
EOFFACTORIES

echo -e "${GREEN}   âœ… tests/factories/index.ts${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 96: tests/mocks/handlers.ts - MSW Handlers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [96/150] tests/mocks/handlers.ts${NC}"

cat > tests/mocks/handlers.ts << 'EOFMSWHANDLERS'
import { http, HttpResponse, delay } from 'msw';
import { userFactory, productFactory, orderFactory } from '../factories';

const API = process.env.API_URL || 'http://localhost:3000/api';

export const authHandlers = [
  http.post(`${API}/auth/login`, async ({ request }) => {
    const body = await request.json() as { email: string; password: string };
    if (body.email === 'test@example.com' && body.password === 'Test123!@#') {
      return HttpResponse.json({ user: userFactory.build({ email: body.email }), token: 'mock-jwt' });
    }
    await delay(500);
    return HttpResponse.json({ error: 'Invalid credentials' }, { status: 401 });
  }),
  http.post(`${API}/auth/logout`, () => HttpResponse.json({ success: true })),
  http.get(`${API}/auth/me`, ({ request }) => {
    if (!request.headers.get('Authorization')?.startsWith('Bearer ')) {
      return HttpResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }
    return HttpResponse.json(userFactory.build());
  }),
];

export const userHandlers = [
  http.get(`${API}/users`, () => HttpResponse.json({
    data: userFactory.buildList(10),
    meta: { total: 100, page: 1, limit: 10 },
  })),
  http.get(`${API}/users/:id`, ({ params }) => {
    if (params.id === 'not-found') return HttpResponse.json({ error: 'Not found' }, { status: 404 });
    return HttpResponse.json(userFactory.build({ id: params.id as string }));
  }),
  http.post(`${API}/users`, async ({ request }) => {
    const body = await request.json();
    return HttpResponse.json(userFactory.build(body as any), { status: 201 });
  }),
];

export const productHandlers = [
  http.get(`${API}/products`, ({ request }) => {
    const url = new URL(request.url);
    const limit = parseInt(url.searchParams.get('limit') || '10');
    return HttpResponse.json({ data: productFactory.buildList(limit), meta: { total: 100, page: 1, limit } });
  }),
];

export const orderHandlers = [
  http.get(`${API}/orders`, () => HttpResponse.json({ data: orderFactory.buildList(5), meta: { total: 50 } })),
  http.post(`${API}/orders`, async ({ request }) => {
    const body = await request.json();
    await delay(1000);
    return HttpResponse.json(orderFactory.build({ status: 'pending', ...body as any }), { status: 201 });
  }),
];

export const handlers = [...authHandlers, ...userHandlers, ...productHandlers, ...orderHandlers];
EOFMSWHANDLERS

echo -e "${GREEN}   âœ… tests/mocks/handlers.ts${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 97: tests/mocks/server.ts - MSW Server
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [97/150] tests/mocks/server.ts${NC}"

cat > tests/mocks/server.ts << 'EOFMSWSERVER'
import { setupServer } from 'msw/node';
import { handlers } from './handlers';

export const server = setupServer(...handlers);

export function setupMockServer() {
  beforeAll(() => server.listen({ onUnhandledRequest: 'warn' }));
  afterEach(() => server.resetHandlers());
  afterAll(() => server.close());
}

export function addHandler(...customHandlers: Parameters<typeof server.use>) {
  server.use(...customHandlers);
}
EOFMSWSERVER

echo -e "${GREEN}   âœ… tests/mocks/server.ts${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 98: tests/contract/pact.config.ts - Contract Testing
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [98/150] tests/contract/pact.config.ts${NC}"

cat > tests/contract/pact.config.ts << 'EOFPACTCONFIG'
import path from 'path';

export const pactConfig = {
  consumer: process.env.PACT_CONSUMER || 'frontend',
  provider: process.env.PACT_PROVIDER || 'api',
  pactDir: path.resolve(process.cwd(), 'pacts'),
  logDir: path.resolve(process.cwd(), 'logs/pact'),
  mockServerPort: parseInt(process.env.PACT_MOCK_PORT || '9999'),
  pactBrokerUrl: process.env.PACT_BROKER_URL,
  pactBrokerToken: process.env.PACT_BROKER_TOKEN,
  publishVerificationResult: process.env.CI === 'true',
  providerVersion: process.env.GIT_COMMIT || process.env.npm_package_version || '1.0.0',
  logLevel: (process.env.PACT_LOG_LEVEL || 'info') as 'trace' | 'debug' | 'info' | 'warn' | 'error',
};

export const consumerVersionSelectors = [
  { mainBranch: true },
  { deployedOrReleased: true },
  { branch: process.env.GIT_BRANCH || 'main' },
];
EOFPACTCONFIG

echo -e "${GREEN}   âœ… tests/contract/pact.config.ts${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 99: tests/contract/consumer/userApi.pact.spec.ts
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [99/150] tests/contract/consumer/userApi.pact.spec.ts${NC}"

cat > tests/contract/consumer/userApi.pact.spec.ts << 'EOFPACTCONSUMER'
import { PactV3, MatchersV3 } from '@pact-foundation/pact';
import { pactConfig } from '../pact.config';

const { like, eachLike, regex, uuid, iso8601DateTime } = MatchersV3;

const provider = new PactV3({
  consumer: pactConfig.consumer,
  provider: pactConfig.provider,
  dir: pactConfig.pactDir,
  logLevel: pactConfig.logLevel,
});

describe('User API Contract', () => {
  describe('GET /api/users/:id', () => {
    it('should return a user by ID', async () => {
      const expectedUser = {
        id: uuid(),
        email: regex(/^[\w-\.]+@([\w-]+\.)+[\w-]{2,4}$/, 'user@example.com'),
        name: like('John Doe'),
        role: like('user'),
        createdAt: iso8601DateTime(),
      };

      await provider
        .given('a user exists')
        .uponReceiving('a request for a user by ID')
        .withRequest({
          method: 'GET',
          path: regex(/\/api\/users\/[a-f0-9-]+/, '/api/users/123e4567-e89b-12d3-a456-426614174000'),
          headers: { Authorization: like('Bearer token123') },
        })
        .willRespondWith({
          status: 200,
          headers: { 'Content-Type': 'application/json' },
          body: expectedUser,
        });

      await provider.executeTest(async (mockServer) => {
        const response = await fetch(`${mockServer.url}/api/users/123e4567-e89b-12d3-a456-426614174000`, {
          headers: { Authorization: 'Bearer token123' },
        });
        expect(response.status).toBe(200);
        const user = await response.json();
        expect(user).toHaveProperty('id');
        expect(user).toHaveProperty('email');
      });
    });

    it('should return 404 for non-existent user', async () => {
      await provider
        .given('a user does not exist')
        .uponReceiving('a request for a non-existent user')
        .withRequest({
          method: 'GET',
          path: '/api/users/non-existent-id',
          headers: { Authorization: like('Bearer token123') },
        })
        .willRespondWith({
          status: 404,
          headers: { 'Content-Type': 'application/json' },
          body: { error: 'Not Found', message: like('User not found') },
        });

      await provider.executeTest(async (mockServer) => {
        const response = await fetch(`${mockServer.url}/api/users/non-existent-id`, {
          headers: { Authorization: 'Bearer token123' },
        });
        expect(response.status).toBe(404);
      });
    });
  });
});
EOFPACTCONSUMER

echo -e "${GREEN}   âœ… tests/contract/consumer/userApi.pact.spec.ts${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 100: tests/smoke/smoke.spec.ts - Smoke Tests
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [100/150] tests/smoke/smoke.spec.ts${NC}"

cat > tests/smoke/smoke.spec.ts << 'EOFSMOKESPEC'
import { test, expect } from '@playwright/test';

const BASE_URL = process.env.SMOKE_TEST_URL || 'http://localhost:3000';

test.describe('Smoke Tests', () => {
  test.describe.configure({ mode: 'parallel', retries: 2 });

  test.describe('Health Checks', () => {
    test('API health should be healthy', async ({ request }) => {
      const response = await request.get(`${BASE_URL}/health`);
      expect(response.status()).toBe(200);
      const body = await response.json();
      expect(body.status).toBe('healthy');
    });

    test('API ready should be ready', async ({ request }) => {
      const response = await request.get(`${BASE_URL}/ready`);
      expect(response.status()).toBe(200);
    });
  });

  test.describe('Critical Pages', () => {
    test('Home page should load', async ({ request }) => {
      const response = await request.get(BASE_URL);
      expect(response.status()).toBe(200);
      const body = await response.text();
      expect(body.toLowerCase()).toContain('html');
    });

    test('Login page should load', async ({ request }) => {
      const response = await request.get(`${BASE_URL}/login`);
      expect(response.status()).toBe(200);
    });
  });

  test.describe('Performance', () => {
    test('Home should load under 3s', async ({ page }) => {
      const start = Date.now();
      await page.goto(BASE_URL);
      expect(Date.now() - start).toBeLessThan(3000);
    });

    test('Health should respond under 500ms', async ({ request }) => {
      const start = Date.now();
      await request.get(`${BASE_URL}/health`);
      expect(Date.now() - start).toBeLessThan(500);
    });
  });
});
EOFSMOKESPEC

echo -e "${GREEN}   âœ… tests/smoke/smoke.spec.ts${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 101: stryker.conf.json - Mutation Testing
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [101/150] stryker.conf.json${NC}"

cat > stryker.conf.json << 'EOFSTRYKER'
{
  "$schema": "./node_modules/@stryker-mutator/core/schema/stryker-schema.json",
  "packageManager": "npm",
  "reporters": ["html", "clear-text", "progress", "json"],
  "testRunner": "vitest",
  "coverageAnalysis": "perTest",
  "mutate": [
    "src/**/*.ts",
    "!src/**/*.spec.ts",
    "!src/**/*.test.ts",
    "!src/**/*.d.ts",
    "!src/**/index.ts"
  ],
  "thresholds": { "high": 80, "low": 60, "break": 50 },
  "concurrency": 4,
  "timeoutMS": 60000,
  "htmlReporter": { "fileName": "reports/mutation/index.html" },
  "jsonReporter": { "fileName": "reports/mutation/mutation-report.json" },
  "incremental": true,
  "incrementalFile": ".stryker-tmp/incremental.json"
}
EOFSTRYKER

echo -e "${GREEN}   âœ… stryker.conf.json${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 102: .github/workflows/e2e.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [102/150] .github/workflows/e2e.yml${NC}"

cat > .github/workflows/e2e.yml << 'EOFE2EYML'
name: ğŸ­ E2E Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  e2e-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, firefox, webkit]
        shard: [1/3, 2/3, 3/3]

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test
        ports: ["5432:5432"]
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      - run: npm ci
      - run: npx playwright install --with-deps ${{ matrix.browser }}
      - run: npm run db:migrate && npm run db:seed:test
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test
      - run: npm run build
      - name: Run E2E tests
        run: npx playwright test --project=${{ matrix.browser }} --shard=${{ matrix.shard }}
        env:
          BASE_URL: http://localhost:3000
          DATABASE_URL: postgresql://test:test@localhost:5432/test
      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report-${{ matrix.browser }}-${{ strategy.job-index }}
          path: reports/playwright/
          retention-days: 30
EOFE2EYML

echo -e "${GREEN}   âœ… .github/workflows/e2e.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 103: scripts/run-smoke-tests.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [103/150] scripts/run-smoke-tests.sh${NC}"

cat > scripts/run-smoke-tests.sh << 'EOFSMOKERUN'
#!/bin/bash
set -e

URL="${1:-$SMOKE_TEST_URL}"
URL="${URL:-http://localhost:3000}"

echo "ğŸ”¥ SMOKE TESTS - $URL"

# Verificar conectividade
if ! curl -s --max-time 10 "$URL/health" > /dev/null; then
    echo "âŒ URL nÃ£o acessÃ­vel: $URL"
    exit 1
fi
echo "âœ… URL acessÃ­vel"

# Executar testes
SMOKE_TEST_URL="$URL" npx playwright test tests/smoke --reporter=list --timeout=30000 --retries=2

if [ $? -eq 0 ]; then
    echo "âœ… SMOKE TESTS PASSARAM - DEPLOY VALIDADO!"
else
    echo "âŒ SMOKE TESTS FALHARAM - VERIFICAR DEPLOY!"
    [ -f "./scripts/notify-discord.sh" ] && ./scripts/notify-discord.sh alert critical "Smoke Tests Failed" "Deploy em $URL falhou"
    exit 1
fi
EOFSMOKERUN

chmod +x scripts/run-smoke-tests.sh
echo -e "${GREEN}   âœ… scripts/run-smoke-tests.sh${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸ“Š PARTE 2: v7.2 OBSERVABILITY COMPLETE
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸ“Š PARTE 2: v7.2 OBSERVABILITY COMPLETE                                    â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 104: monitoring/grafana/dashboards/application-overview.json
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [104/150] monitoring/grafana/dashboards/application-overview.json${NC}"

cat > monitoring/grafana/dashboards/application-overview.json << 'EOFGRAFANA1'
{
  "title": "Application Overview",
  "uid": "app-overview",
  "tags": ["application", "overview"],
  "refresh": "30s",
  "time": { "from": "now-1h", "to": "now" },
  "panels": [
    {
      "id": 1, "title": "Requests/sec", "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 0, "y": 0 },
      "targets": [{ "expr": "sum(rate(http_requests_total[5m]))", "refId": "A" }],
      "fieldConfig": { "defaults": { "thresholds": { "steps": [{ "color": "green", "value": null }] } } }
    },
    {
      "id": 2, "title": "Error Rate", "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 6, "y": 0 },
      "targets": [{ "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) * 100", "refId": "A" }],
      "fieldConfig": { "defaults": { "unit": "percent", "thresholds": { "steps": [{ "color": "green", "value": null }, { "color": "yellow", "value": 1 }, { "color": "red", "value": 5 }] } } }
    },
    {
      "id": 3, "title": "P95 Latency", "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 12, "y": 0 },
      "targets": [{ "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) * 1000", "refId": "A" }],
      "fieldConfig": { "defaults": { "unit": "ms", "thresholds": { "steps": [{ "color": "green", "value": null }, { "color": "yellow", "value": 200 }, { "color": "red", "value": 500 }] } } }
    },
    {
      "id": 4, "title": "Availability (24h)", "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 18, "y": 0 },
      "targets": [{ "expr": "(1 - sum(rate(http_requests_total{status=~\"5..\"}[24h])) / sum(rate(http_requests_total[24h]))) * 100", "refId": "A" }],
      "fieldConfig": { "defaults": { "unit": "percent", "thresholds": { "steps": [{ "color": "red", "value": null }, { "color": "yellow", "value": 95 }, { "color": "green", "value": 99 }] } } }
    },
    {
      "id": 5, "title": "Requests by Status Code", "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 4 },
      "targets": [{ "expr": "sum(rate(http_requests_total[5m])) by (status)", "legendFormat": "{{status}}", "refId": "A" }]
    },
    {
      "id": 6, "title": "Response Time Percentiles", "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 4 },
      "targets": [
        { "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) * 1000", "legendFormat": "P50", "refId": "A" },
        { "expr": "histogram_quantile(0.90, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) * 1000", "legendFormat": "P90", "refId": "B" },
        { "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) * 1000", "legendFormat": "P99", "refId": "C" }
      ],
      "fieldConfig": { "defaults": { "unit": "ms" } }
    }
  ]
}
EOFGRAFANA1

echo -e "${GREEN}   âœ… monitoring/grafana/dashboards/application-overview.json${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 105: monitoring/grafana/dashboards/nodejs-metrics.json
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [105/150] monitoring/grafana/dashboards/nodejs-metrics.json${NC}"

cat > monitoring/grafana/dashboards/nodejs-metrics.json << 'EOFGRAFANA2'
{
  "title": "Node.js Runtime Metrics",
  "uid": "nodejs-metrics",
  "tags": ["nodejs", "runtime"],
  "refresh": "30s",
  "panels": [
    {
      "id": 1, "title": "Heap Usage %", "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 0, "y": 0 },
      "targets": [{ "expr": "nodejs_heap_size_used_bytes / nodejs_heap_size_total_bytes * 100", "refId": "A" }],
      "fieldConfig": { "defaults": { "unit": "percent", "thresholds": { "steps": [{ "color": "green", "value": null }, { "color": "yellow", "value": 70 }, { "color": "red", "value": 85 }] } } }
    },
    {
      "id": 2, "title": "Heap Used", "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 6, "y": 0 },
      "targets": [{ "expr": "nodejs_heap_size_used_bytes", "refId": "A" }],
      "fieldConfig": { "defaults": { "unit": "bytes" } }
    },
    {
      "id": 3, "title": "Active Handles", "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 12, "y": 0 },
      "targets": [{ "expr": "nodejs_active_handles_total", "refId": "A" }]
    },
    {
      "id": 4, "title": "Event Loop Lag", "type": "stat",
      "gridPos": { "h": 4, "w": 6, "x": 18, "y": 0 },
      "targets": [{ "expr": "nodejs_eventloop_lag_seconds", "refId": "A" }],
      "fieldConfig": { "defaults": { "unit": "s" } }
    },
    {
      "id": 5, "title": "Memory Usage", "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 4 },
      "targets": [
        { "expr": "nodejs_heap_size_total_bytes", "legendFormat": "Total", "refId": "A" },
        { "expr": "nodejs_heap_size_used_bytes", "legendFormat": "Used", "refId": "B" },
        { "expr": "nodejs_external_memory_bytes", "legendFormat": "External", "refId": "C" }
      ],
      "fieldConfig": { "defaults": { "unit": "bytes" } }
    },
    {
      "id": 6, "title": "GC Duration", "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 4 },
      "targets": [{ "expr": "rate(nodejs_gc_duration_seconds_sum[5m])", "legendFormat": "GC Duration", "refId": "A" }]
    }
  ]
}
EOFGRAFANA2

echo -e "${GREEN}   âœ… monitoring/grafana/dashboards/nodejs-metrics.json${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 106: monitoring/prometheus/rules/application-alerts.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [106/150] monitoring/prometheus/rules/application-alerts.yml${NC}"

cat > monitoring/prometheus/rules/application-alerts.yml << 'EOFALERTS1'
groups:
  - name: application.availability
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) * 100 > 5
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "High error rate: {{ $value | printf \"%.2f\" }}%"
          runbook_url: "https://runbooks.example.com/high-error-rate"

      - alert: ServiceDown
        expr: up{job="app"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.instance }} is down"

      - alert: HighLatency
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "P95 latency is {{ $value | printf \"%.2f\" }}s"

  - name: application.resources
    interval: 30s
    rules:
      - alert: HighMemoryUsage
        expr: (nodejs_heap_size_used_bytes / nodejs_heap_size_total_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Heap usage is {{ $value | printf \"%.2f\" }}%"

      - alert: HighCPUUsage
        expr: rate(process_cpu_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CPU usage is {{ $value | printf \"%.2f\" }}%"

      - alert: EventLoopLag
        expr: nodejs_eventloop_lag_seconds > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Event loop lag is {{ $value | printf \"%.3f\" }}s"
EOFALERTS1

echo -e "${GREEN}   âœ… monitoring/prometheus/rules/application-alerts.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 107: monitoring/prometheus/rules/infrastructure-alerts.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [107/150] monitoring/prometheus/rules/infrastructure-alerts.yml${NC}"

cat > monitoring/prometheus/rules/infrastructure-alerts.yml << 'EOFALERTS2'
groups:
  - name: infrastructure.database
    interval: 30s
    rules:
      - alert: DatabaseDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          team: dba
        annotations:
          summary: "PostgreSQL {{ $labels.instance }} is down"

      - alert: DatabaseConnectionsExhausted
        expr: pg_stat_activity_count / pg_settings_max_connections * 100 > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "{{ $value | printf \"%.2f\" }}% of DB connections in use"

      - alert: DatabaseSlowQueries
        expr: rate(pg_stat_statements_seconds_total[5m]) / rate(pg_stat_statements_calls_total[5m]) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Average query time is {{ $value | printf \"%.2f\" }}s"

  - name: infrastructure.redis
    interval: 30s
    rules:
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis {{ $labels.instance }} is down"

      - alert: RedisHighMemory
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Redis memory is {{ $value | printf \"%.2f\" }}% full"

  - name: infrastructure.system
    interval: 30s
    rules:
      - alert: HostHighCPU
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Host CPU usage is {{ $value | printf \"%.2f\" }}%"

      - alert: HostHighMemory
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Host memory usage is {{ $value | printf \"%.2f\" }}%"

      - alert: HostDiskFull
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Disk {{ $labels.mountpoint }} is {{ $value | printf \"%.2f\" }}% full"
EOFALERTS2

echo -e "${GREEN}   âœ… monitoring/prometheus/rules/infrastructure-alerts.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 108: monitoring/prometheus/rules/slo-alerts.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [108/150] monitoring/prometheus/rules/slo-alerts.yml${NC}"

cat > monitoring/prometheus/rules/slo-alerts.yml << 'EOFSLOALERTS'
groups:
  - name: slo.availability
    interval: 1m
    rules:
      # Recording rules
      - record: sli:availability:ratio_rate5m
        expr: sum(rate(http_requests_total{status!~"5.."}[5m])) / sum(rate(http_requests_total[5m]))

      - record: sli:availability:ratio_rate1h
        expr: sum(rate(http_requests_total{status!~"5.."}[1h])) / sum(rate(http_requests_total[1h]))

      # Burn rate alerts
      - alert: SLOAvailabilityBurnRateCritical
        expr: ((1 - sli:availability:ratio_rate1h) / (1 - 0.999)) > 14.4
        for: 2m
        labels:
          severity: critical
          slo: availability
        annotations:
          summary: "Critical: Burning error budget 14x faster than allowed"

      - alert: SLOAvailabilityBurnRateHigh
        expr: ((1 - sli:availability:ratio_rate1h) / (1 - 0.999)) > 6
        for: 15m
        labels:
          severity: warning
          slo: availability
        annotations:
          summary: "Warning: Burning error budget 6x faster than allowed"

      - alert: SLOErrorBudgetLow
        expr: (1 - ((1 - sli:availability:ratio_rate1h) / (1 - 0.999))) < 0.2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Error budget below 20% - consider freezing changes"

  - name: slo.latency
    interval: 1m
    rules:
      - record: sli:latency:p95_5m
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))

      - record: sli:latency:p99_5m
        expr: histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))

      - alert: SLOLatencyP95Breach
        expr: sli:latency:p95_5m > 0.5
        for: 5m
        labels:
          severity: warning
          slo: latency
        annotations:
          summary: "P95 latency {{ $value | printf \"%.2f\" }}s exceeds SLO (500ms)"

      - alert: SLOLatencyP99Breach
        expr: sli:latency:p99_5m > 1.0
        for: 5m
        labels:
          severity: warning
          slo: latency
        annotations:
          summary: "P99 latency {{ $value | printf \"%.2f\" }}s exceeds SLO (1s)"
EOFSLOALERTS

echo -e "${GREEN}   âœ… monitoring/prometheus/rules/slo-alerts.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 109: monitoring/alertmanager/alertmanager.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [109/150] monitoring/alertmanager/alertmanager.yml${NC}"

cat > monitoring/alertmanager/alertmanager.yml << 'EOFALERTMANAGER'
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: '${SMTP_USER}'
  smtp_auth_password: '${SMTP_PASSWORD}'
  slack_api_url: '${SLACK_WEBHOOK_URL}'

route:
  receiver: 'default-receiver'
  group_by: ['alertname', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  routes:
    - match:
        severity: critical
      receiver: 'critical-receiver'
      continue: true
    - match:
        severity: warning
      receiver: 'warning-receiver'
    - match:
        team: dba
      receiver: 'dba-receiver'

receivers:
  - name: 'default-receiver'
    slack_configs:
      - channel: '#alerts'
        title: '{{ .CommonAnnotations.summary }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

  - name: 'critical-receiver'
    slack_configs:
      - channel: '#alerts-critical'
        title: 'ğŸš¨ CRITICAL: {{ .CommonAnnotations.summary }}'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        severity: critical

  - name: 'warning-receiver'
    slack_configs:
      - channel: '#alerts'
        title: 'âš ï¸ Warning: {{ .CommonAnnotations.summary }}'

  - name: 'dba-receiver'
    slack_configs:
      - channel: '#dba-alerts'
        title: 'ğŸ—„ï¸ Database: {{ .CommonAnnotations.summary }}'
    email_configs:
      - to: 'dba-team@example.com'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
EOFALERTMANAGER

echo -e "${GREEN}   âœ… monitoring/alertmanager/alertmanager.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 110: docs/slo/SLO_DEFINITIONS.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [110/150] docs/slo/SLO_DEFINITIONS.md${NC}"

cat > docs/slo/SLO_DEFINITIONS.md << 'EOFSLODEF'
# ğŸ“‹ SLI/SLO/SLA Definitions

## Conceitos

| Termo | DescriÃ§Ã£o | Exemplo |
|-------|-----------|---------|
| **SLI** | Service Level Indicator - MÃ©trica | % requests com sucesso |
| **SLO** | Service Level Objective - Meta interna | 99.9% sucesso |
| **SLA** | Service Level Agreement - Contrato | 99.5% uptime garantido |
| **Error Budget** | Quanto podemos falhar | 0.1% = 43 min/mÃªs |

## SLOs do Sistema

### ğŸŸ¢ Availability SLO

| MÃ©trica | SLI Query | SLO | Error Budget (30d) |
|---------|-----------|-----|-------------------|
| Uptime | `(requests com sucesso) / (total)` | 99.9% | 43 minutos |

### âš¡ Latency SLO

| Percentil | SLO | Query |
|-----------|-----|-------|
| P50 | < 100ms | `histogram_quantile(0.5, ...)` |
| P95 | < 500ms | `histogram_quantile(0.95, ...)` |
| P99 | < 1000ms | `histogram_quantile(0.99, ...)` |

## Error Budget Policy

| Budget Restante | AÃ§Ãµes |
|-----------------|-------|
| > 50% | âœ… Deploy normal, experimentos OK |
| 20-50% | âš ï¸ Deploy com cautela, reduzir experimentos |
| < 20% | ğŸ›‘ Freeze de features, foco em estabilidade |
| 0% | ğŸš¨ Incident response, postmortem obrigatÃ³rio |

## Prometheus Queries

```promql
# Availability SLI
sum(rate(http_requests_total{status!~"5.."}[30d])) / sum(rate(http_requests_total[30d]))

# Error Budget restante
1 - ((1 - sli:availability:ratio_rate30d) / (1 - 0.999))
```
EOFSLODEF

echo -e "${GREEN}   âœ… docs/slo/SLO_DEFINITIONS.md${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸ—ï¸ PARTE 3: v8.0 INFRASTRUCTURE AS CODE
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸ—ï¸ PARTE 3: v8.0 INFRASTRUCTURE AS CODE                                    â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 111: infrastructure/terraform/main.tf
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [111/150] infrastructure/terraform/main.tf${NC}"

cat > infrastructure/terraform/main.tf << 'EOFTFMAIN'
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Terraform Main Configuration
# Multi-Agent System v8.0 - Ultimate Edition
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

terraform {
  required_version = ">= 1.5.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
    helm = {
      source  = "hashicorp/helm"
      version = "~> 2.11"
    }
  }

  backend "s3" {
    bucket         = "terraform-state-${var.project_name}"
    key            = "${var.environment}/terraform.tfstate"
    region         = var.aws_region
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}

provider "aws" {
  region = var.aws_region

  default_tags {
    tags = {
      Project     = var.project_name
      Environment = var.environment
      ManagedBy   = "terraform"
    }
  }
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA SOURCES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

data "aws_availability_zones" "available" {
  state = "available"
}

data "aws_caller_identity" "current" {}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODULES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

module "vpc" {
  source = "./modules/vpc"

  project_name = var.project_name
  environment  = var.environment
  vpc_cidr     = var.vpc_cidr
  azs          = slice(data.aws_availability_zones.available.names, 0, 3)
}

module "eks" {
  source = "./modules/eks"

  project_name       = var.project_name
  environment        = var.environment
  vpc_id             = module.vpc.vpc_id
  private_subnet_ids = module.vpc.private_subnet_ids
  cluster_version    = var.eks_cluster_version
  node_instance_type = var.eks_node_instance_type
  node_desired_size  = var.eks_node_desired_size
  node_min_size      = var.eks_node_min_size
  node_max_size      = var.eks_node_max_size
}

module "rds" {
  source = "./modules/rds"

  project_name       = var.project_name
  environment        = var.environment
  vpc_id             = module.vpc.vpc_id
  private_subnet_ids = module.vpc.private_subnet_ids
  instance_class     = var.rds_instance_class
  allocated_storage  = var.rds_allocated_storage
  db_name            = var.db_name
  db_username        = var.db_username
  eks_security_group = module.eks.node_security_group_id
}

module "redis" {
  source = "./modules/redis"

  project_name       = var.project_name
  environment        = var.environment
  vpc_id             = module.vpc.vpc_id
  private_subnet_ids = module.vpc.private_subnet_ids
  node_type          = var.redis_node_type
  eks_security_group = module.eks.node_security_group_id
}

module "s3" {
  source = "./modules/s3"

  project_name = var.project_name
  environment  = var.environment
  buckets      = var.s3_buckets
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OUTPUTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

output "vpc_id" {
  value = module.vpc.vpc_id
}

output "eks_cluster_endpoint" {
  value = module.eks.cluster_endpoint
}

output "eks_cluster_name" {
  value = module.eks.cluster_name
}

output "rds_endpoint" {
  value     = module.rds.endpoint
  sensitive = true
}

output "redis_endpoint" {
  value     = module.redis.endpoint
  sensitive = true
}
EOFTFMAIN

echo -e "${GREEN}   âœ… infrastructure/terraform/main.tf${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 112: infrastructure/terraform/variables.tf
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [112/150] infrastructure/terraform/variables.tf${NC}"

cat > infrastructure/terraform/variables.tf << 'EOFTFVARS'
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Terraform Variables
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# General
variable "project_name" {
  description = "Project name"
  type        = string
}

variable "environment" {
  description = "Environment (dev, staging, prod)"
  type        = string
}

variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

# VPC
variable "vpc_cidr" {
  description = "VPC CIDR block"
  type        = string
  default     = "10.0.0.0/16"
}

# EKS
variable "eks_cluster_version" {
  description = "Kubernetes version"
  type        = string
  default     = "1.28"
}

variable "eks_node_instance_type" {
  description = "EC2 instance type for EKS nodes"
  type        = string
  default     = "t3.medium"
}

variable "eks_node_desired_size" {
  description = "Desired number of EKS nodes"
  type        = number
  default     = 2
}

variable "eks_node_min_size" {
  description = "Minimum number of EKS nodes"
  type        = number
  default     = 1
}

variable "eks_node_max_size" {
  description = "Maximum number of EKS nodes"
  type        = number
  default     = 5
}

# RDS
variable "rds_instance_class" {
  description = "RDS instance class"
  type        = string
  default     = "db.t3.medium"
}

variable "rds_allocated_storage" {
  description = "RDS allocated storage in GB"
  type        = number
  default     = 20
}

variable "db_name" {
  description = "Database name"
  type        = string
}

variable "db_username" {
  description = "Database username"
  type        = string
  sensitive   = true
}

# Redis
variable "redis_node_type" {
  description = "ElastiCache node type"
  type        = string
  default     = "cache.t3.micro"
}

# S3
variable "s3_buckets" {
  description = "S3 buckets to create"
  type        = list(string)
  default     = ["uploads", "backups", "logs"]
}
EOFTFVARS

echo -e "${GREEN}   âœ… infrastructure/terraform/variables.tf${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 113: infrastructure/terraform/modules/vpc/main.tf
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [113/150] infrastructure/terraform/modules/vpc/main.tf${NC}"

cat > infrastructure/terraform/modules/vpc/main.tf << 'EOFTFVPC'
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VPC Module
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

variable "project_name" { type = string }
variable "environment" { type = string }
variable "vpc_cidr" { type = string }
variable "azs" { type = list(string) }

locals {
  name = "${var.project_name}-${var.environment}"
}

resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = { Name = "${local.name}-vpc" }
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  tags   = { Name = "${local.name}-igw" }
}

resource "aws_subnet" "public" {
  count                   = length(var.azs)
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(var.vpc_cidr, 4, count.index)
  availability_zone       = var.azs[count.index]
  map_public_ip_on_launch = true

  tags = {
    Name                     = "${local.name}-public-${var.azs[count.index]}"
    "kubernetes.io/role/elb" = "1"
  }
}

resource "aws_subnet" "private" {
  count             = length(var.azs)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 4, count.index + length(var.azs))
  availability_zone = var.azs[count.index]

  tags = {
    Name                              = "${local.name}-private-${var.azs[count.index]}"
    "kubernetes.io/role/internal-elb" = "1"
  }
}

resource "aws_eip" "nat" {
  count  = length(var.azs)
  domain = "vpc"
  tags   = { Name = "${local.name}-nat-eip-${count.index}" }
}

resource "aws_nat_gateway" "main" {
  count         = length(var.azs)
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id
  tags          = { Name = "${local.name}-nat-${count.index}" }
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }
  tags = { Name = "${local.name}-public-rt" }
}

resource "aws_route_table" "private" {
  count  = length(var.azs)
  vpc_id = aws_vpc.main.id
  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.main[count.index].id
  }
  tags = { Name = "${local.name}-private-rt-${count.index}" }
}

resource "aws_route_table_association" "public" {
  count          = length(var.azs)
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

resource "aws_route_table_association" "private" {
  count          = length(var.azs)
  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = aws_route_table.private[count.index].id
}

output "vpc_id" { value = aws_vpc.main.id }
output "public_subnet_ids" { value = aws_subnet.public[*].id }
output "private_subnet_ids" { value = aws_subnet.private[*].id }
EOFTFVPC

echo -e "${GREEN}   âœ… infrastructure/terraform/modules/vpc/main.tf${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 114: infrastructure/terraform/modules/eks/main.tf
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [114/150] infrastructure/terraform/modules/eks/main.tf${NC}"

cat > infrastructure/terraform/modules/eks/main.tf << 'EOFTFEKS'
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EKS Module
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

variable "project_name" { type = string }
variable "environment" { type = string }
variable "vpc_id" { type = string }
variable "private_subnet_ids" { type = list(string) }
variable "cluster_version" { type = string }
variable "node_instance_type" { type = string }
variable "node_desired_size" { type = number }
variable "node_min_size" { type = number }
variable "node_max_size" { type = number }

locals {
  name = "${var.project_name}-${var.environment}"
}

# IAM Role for EKS Cluster
resource "aws_iam_role" "cluster" {
  name = "${local.name}-eks-cluster-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = { Service = "eks.amazonaws.com" }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "cluster_policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role       = aws_iam_role.cluster.name
}

# IAM Role for Node Group
resource "aws_iam_role" "node" {
  name = "${local.name}-eks-node-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = { Service = "ec2.amazonaws.com" }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "node_worker" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
  role       = aws_iam_role.node.name
}

resource "aws_iam_role_policy_attachment" "node_cni" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
  role       = aws_iam_role.node.name
}

resource "aws_iam_role_policy_attachment" "node_ecr" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  role       = aws_iam_role.node.name
}

# Security Group
resource "aws_security_group" "cluster" {
  name        = "${local.name}-eks-cluster-sg"
  description = "EKS cluster security group"
  vpc_id      = var.vpc_id

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = { Name = "${local.name}-eks-cluster-sg" }
}

# EKS Cluster
resource "aws_eks_cluster" "main" {
  name     = "${local.name}-cluster"
  role_arn = aws_iam_role.cluster.arn
  version  = var.cluster_version

  vpc_config {
    subnet_ids              = var.private_subnet_ids
    endpoint_private_access = true
    endpoint_public_access  = true
    security_group_ids      = [aws_security_group.cluster.id]
  }

  depends_on = [aws_iam_role_policy_attachment.cluster_policy]
}

# Node Group
resource "aws_eks_node_group" "main" {
  cluster_name    = aws_eks_cluster.main.name
  node_group_name = "${local.name}-node-group"
  node_role_arn   = aws_iam_role.node.arn
  subnet_ids      = var.private_subnet_ids
  instance_types  = [var.node_instance_type]

  scaling_config {
    desired_size = var.node_desired_size
    min_size     = var.node_min_size
    max_size     = var.node_max_size
  }

  depends_on = [
    aws_iam_role_policy_attachment.node_worker,
    aws_iam_role_policy_attachment.node_cni,
    aws_iam_role_policy_attachment.node_ecr,
  ]
}

output "cluster_endpoint" { value = aws_eks_cluster.main.endpoint }
output "cluster_name" { value = aws_eks_cluster.main.name }
output "cluster_ca_certificate" { value = aws_eks_cluster.main.certificate_authority[0].data }
output "node_security_group_id" { value = aws_security_group.cluster.id }
EOFTFEKS

echo -e "${GREEN}   âœ… infrastructure/terraform/modules/eks/main.tf${NC}"

rds_allocated_storage = 100
db_name               = "myapp_prod"

# Redis
redis_node_type = "cache.r6g.large"

# S3
s3_buckets = ["uploads", "backups", "logs", "assets"]
EOFTFPROD

echo -e "${GREEN}   âœ… infrastructure/terraform/environments/prod/terraform.tfvars${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 119: infrastructure/kubernetes/base/deployment.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [119/150] infrastructure/kubernetes/base/deployment.yaml${NC}"

cat > infrastructure/kubernetes/base/deployment.yaml << 'EOFK8SDEPLOY'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
  labels:
    app: app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: app
  template:
    metadata:
      labels:
        app: app
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "3000"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: app
      containers:
        - name: app
          image: app:latest
          ports:
            - containerPort: 3000
              name: http
          env:
            - name: NODE_ENV
              value: "production"
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: app-secrets
                  key: database-url
            - name: REDIS_URL
              valueFrom:
                secretKeyRef:
                  name: app-secrets
                  key: redis-url
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
          livenessProbe:
            httpGet:
              path: /health
              port: 3000
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ready
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 3
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            readOnlyRootFilesystem: true
            allowPrivilegeEscalation: false
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: app
                topologyKey: kubernetes.io/hostname
EOFK8SDEPLOY

echo -e "${GREEN}   âœ… infrastructure/kubernetes/base/deployment.yaml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 120: infrastructure/kubernetes/base/service.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [120/150] infrastructure/kubernetes/base/service.yaml${NC}"

cat > infrastructure/kubernetes/base/service.yaml << 'EOFK8SSVC'
apiVersion: v1
kind: Service
metadata:
  name: app
  labels:
    app: app
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 3000
      protocol: TCP
      name: http
  selector:
    app: app
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/app-role
EOFK8SSVC

echo -e "${GREEN}   âœ… infrastructure/kubernetes/base/service.yaml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 121: infrastructure/kubernetes/base/ingress.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [121/150] infrastructure/kubernetes/base/ingress.yaml${NC}"

cat > infrastructure/kubernetes/base/ingress.yaml << 'EOFK8SINGRESS'
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  tls:
    - hosts:
        - app.example.com
      secretName: app-tls
  rules:
    - host: app.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: app
                port:
                  number: 80
EOFK8SINGRESS

echo -e "${GREEN}   âœ… infrastructure/kubernetes/base/ingress.yaml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 122: infrastructure/kubernetes/base/hpa.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [122/150] infrastructure/kubernetes/base/hpa.yaml${NC}"

cat > infrastructure/kubernetes/base/hpa.yaml << 'EOFK8SHPA'
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app
  minReplicas: 2
  maxReplicas: 20
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 10
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
        - type: Pods
          value: 4
          periodSeconds: 15
      selectPolicy: Max
EOFK8SHPA

echo -e "${GREEN}   âœ… infrastructure/kubernetes/base/hpa.yaml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 123: infrastructure/kubernetes/base/kustomization.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [123/150] infrastructure/kubernetes/base/kustomization.yaml${NC}"

cat > infrastructure/kubernetes/base/kustomization.yaml << 'EOFK8SKUSTOM'
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - deployment.yaml
  - service.yaml
  - ingress.yaml
  - hpa.yaml

commonLabels:
  app.kubernetes.io/name: app
  app.kubernetes.io/managed-by: kustomize
EOFK8SKUSTOM

echo -e "${GREEN}   âœ… infrastructure/kubernetes/base/kustomization.yaml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 124: infrastructure/kubernetes/overlays/prod/kustomization.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [124/150] infrastructure/kubernetes/overlays/prod/kustomization.yaml${NC}"

cat > infrastructure/kubernetes/overlays/prod/kustomization.yaml << 'EOFK8SPROD'
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: production

resources:
  - ../../base

commonLabels:
  environment: production

replicas:
  - name: app
    count: 5

images:
  - name: app
    newName: 123456789.dkr.ecr.us-east-1.amazonaws.com/app
    newTag: latest

patches:
  - patch: |-
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/cpu
        value: "500m"
      - op: replace
        path: /spec/template/spec/containers/0/resources/requests/memory
        value: "512Mi"
      - op: replace
        path: /spec/template/spec/containers/0/resources/limits/cpu
        value: "1000m"
      - op: replace
        path: /spec/template/spec/containers/0/resources/limits/memory
        value: "1Gi"
    target:
      kind: Deployment
      name: app
EOFK8SPROD

echo -e "${GREEN}   âœ… infrastructure/kubernetes/overlays/prod/kustomization.yaml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 125: infrastructure/helm/values.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [125/150] infrastructure/helm/values.yaml${NC}"

cat > infrastructure/helm/values.yaml << 'EOFHELMVALUES'
# Default values for app
replicaCount: 3

image:
  repository: app
  pullPolicy: IfNotPresent
  tag: "latest"

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "3000"

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
  hosts:
    - host: app.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: app-tls
      hosts:
        - app.example.com

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 256Mi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

nodeSelector: {}
tolerations: []
affinity: {}

env:
  NODE_ENV: production

secrets:
  DATABASE_URL: ""
  REDIS_URL: ""
  JWT_SECRET: ""
EOFHELMVALUES

echo -e "${GREEN}   âœ… infrastructure/helm/values.yaml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 126: .github/workflows/terraform.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [126/150] .github/workflows/terraform.yml${NC}"

cat > .github/workflows/terraform.yml << 'EOFTFWORKFLOW'
name: ğŸ—ï¸ Terraform

on:
  push:
    branches: [main]
    paths: ['infrastructure/terraform/**']
  pull_request:
    branches: [main]
    paths: ['infrastructure/terraform/**']

env:
  TF_VERSION: "1.5.7"
  AWS_REGION: "us-east-1"

jobs:
  plan:
    name: ğŸ“‹ Terraform Plan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        environment: [dev, staging, prod]
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Terraform Init
        working-directory: infrastructure/terraform
        run: terraform init -backend-config="environments/${{ matrix.environment }}/backend.tfvars"
      
      - name: Terraform Validate
        working-directory: infrastructure/terraform
        run: terraform validate
      
      - name: Terraform Plan
        working-directory: infrastructure/terraform
        run: terraform plan -var-file="environments/${{ matrix.environment }}/terraform.tfvars" -out=tfplan
      
      - name: Upload Plan
        uses: actions/upload-artifact@v4
        with:
          name: tfplan-${{ matrix.environment }}
          path: infrastructure/terraform/tfplan

  apply:
    name: ğŸš€ Terraform Apply
    needs: plan
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Download Plan
        uses: actions/download-artifact@v4
        with:
          name: tfplan-prod
          path: infrastructure/terraform
      
      - name: Terraform Init
        working-directory: infrastructure/terraform
        run: terraform init -backend-config="environments/prod/backend.tfvars"
      
      - name: Terraform Apply
        working-directory: infrastructure/terraform
        run: terraform apply -auto-approve tfplan
EOFTFWORKFLOW

echo -e "${GREEN}   âœ… .github/workflows/terraform.yml${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸ“š PARTE 4: DOCUMENTAÃ‡ÃƒO E GUIAS COMPLETOS
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸ“š PARTE 4: DOCUMENTAÃ‡ÃƒO E GUIAS COMPLETOS                                 â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 127: TESTING_GUIDE.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [127/150] TESTING_GUIDE.md${NC}"

cat > TESTING_GUIDE.md << 'EOFTESTINGGUIDE'
# ğŸ§ª Complete Testing Guide

## PirÃ¢mide de Testes

```
                    â•±â•²
                   â•±  â•²
                  â•± E2Eâ•²          ~5% - Lento, caro
                 â•±â”€â”€â”€â”€â”€â”€â•²
                â•± Visual â•²        ~5% - Screenshots
               â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
              â•± Integrationâ•²      ~20% - MÃ©dio
             â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
            â•±     Unit       â•²    ~70% - RÃ¡pido
           â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
```

## Quick Commands

```bash
# Unit Tests
npm run test              # Todos
npm run test:watch        # Watch mode
npm run test:coverage     # Com coverage

# E2E Tests (Playwright)
npm run test:e2e          # Todos os browsers
npm run test:e2e:chrome   # SÃ³ Chrome
npm run test:e2e:debug    # Debug mode

# Contract Tests (Pact)
npm run test:contract:consumer
npm run test:contract:provider

# Smoke Tests (pÃ³s-deploy)
./scripts/run-smoke-tests.sh https://staging.app.com

# Mutation Testing
npm run test:mutation
```

## Coverage Targets

| Tipo | Target | Break |
|------|--------|-------|
| Statements | 80% | 70% |
| Branches | 75% | 65% |
| Functions | 80% | 70% |
| Mutation Score | 80% | 50% |

## Estrutura

```
tests/
â”œâ”€â”€ e2e/
â”‚   â”œâ”€â”€ pages/          # Page Objects
â”‚   â”œâ”€â”€ specs/          # Testes E2E
â”‚   â””â”€â”€ fixtures/       # Dados
â”œâ”€â”€ contract/           # Pact
â”œâ”€â”€ smoke/              # Smoke tests
â”œâ”€â”€ factories/          # Test factories
â””â”€â”€ mocks/              # MSW handlers
```
EOFTESTINGGUIDE

echo -e "${GREEN}   âœ… TESTING_GUIDE.md${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 128: INFRASTRUCTURE_GUIDE.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [128/150] INFRASTRUCTURE_GUIDE.md${NC}"

cat > INFRASTRUCTURE_GUIDE.md << 'EOFINFRASTRUCTUREGUIDE'
# ğŸ—ï¸ Infrastructure Guide

## Stack de Infraestrutura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AWS Cloud                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      VPC                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚   â”‚
â”‚  â”‚  â”‚ Public Subnetâ”‚  â”‚ Public Subnetâ”‚  (NAT, ALB)     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚   â”‚
â”‚  â”‚  â”‚Private Subnetâ”‚  â”‚Private Subnetâ”‚  (EKS, RDS)     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                EKS Cluster                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ App â”‚ â”‚ App â”‚ â”‚ App â”‚ â”‚ App â”‚              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜              â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚   RDS    â”‚  â”‚ ElastiC  â”‚  â”‚    S3    â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ Postgres â”‚  â”‚  Redis   â”‚  â”‚  Buckets â”‚          â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Comandos Terraform

```bash
# Inicializar
cd infrastructure/terraform
terraform init -backend-config="environments/prod/backend.tfvars"

# Planejar
terraform plan -var-file="environments/prod/terraform.tfvars"

# Aplicar
terraform apply -var-file="environments/prod/terraform.tfvars"

# Destruir (CUIDADO!)
terraform destroy -var-file="environments/prod/terraform.tfvars"
```

## Kubernetes

```bash
# Aplicar com Kustomize
kubectl apply -k infrastructure/kubernetes/overlays/prod

# Verificar status
kubectl get pods -n production
kubectl get svc -n production

# Logs
kubectl logs -f deployment/app -n production

# Scale
kubectl scale deployment/app --replicas=5 -n production
```

## Ambientes

| Ambiente | DescriÃ§Ã£o | URL |
|----------|-----------|-----|
| dev | Desenvolvimento | dev.app.example.com |
| staging | PrÃ©-produÃ§Ã£o | staging.app.example.com |
| prod | ProduÃ§Ã£o | app.example.com |
EOFINFRASTRUCTUREGUIDE

echo -e "${GREEN}   âœ… INFRASTRUCTURE_GUIDE.md${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 129: OBSERVABILITY_GUIDE.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [129/150] OBSERVABILITY_GUIDE.md${NC}"

cat > OBSERVABILITY_GUIDE.md << 'EOFOBSERVABILITYGUIDE'
# ğŸ“Š Observability Guide

## Stack de Observabilidade

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBSERVABILITY STACK                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Prometheus â”‚  â”‚    Loki     â”‚  â”‚   Jaeger    â”‚         â”‚
â”‚  â”‚   Metrics   â”‚  â”‚    Logs     â”‚  â”‚   Traces    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                â”‚                â”‚                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                          â”‚                                  â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                   â”‚   Grafana   â”‚                           â”‚
â”‚                   â”‚  Dashboards â”‚                           â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                          â”‚                                  â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                   â”‚ Alertmanagerâ”‚                           â”‚
â”‚                   â”‚   Alerts    â”‚                           â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## URLs

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| Grafana | http://localhost:3001 | admin/admin123 |
| Prometheus | http://localhost:9090 | - |
| Jaeger | http://localhost:16686 | - |
| Loki | http://localhost:3100 | - |

## Dashboards DisponÃ­veis

1. **Application Overview** - MÃ©tricas gerais da aplicaÃ§Ã£o
2. **Node.js Metrics** - MÃ©tricas do runtime Node.js
3. **Database Metrics** - MÃ©tricas do PostgreSQL
4. **SLO Dashboard** - Acompanhamento de SLOs

## Alertas Configurados

| Alerta | Severidade | Threshold |
|--------|------------|-----------|
| HighErrorRate | critical | > 5% por 2min |
| ServiceDown | critical | Down por 1min |
| HighLatency | warning | P95 > 1s por 5min |
| HighMemoryUsage | warning | > 85% por 5min |
| DatabaseDown | critical | Down por 1min |
| DiskFull | critical | > 85% |

## Queries Ãšteis

```promql
# Taxa de erro
sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) * 100

# LatÃªncia P95
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))

# Requests por segundo
sum(rate(http_requests_total[5m]))

# Error budget restante
1 - ((1 - sli:availability:ratio_rate24h) / (1 - 0.999))
```
EOFOBSERVABILITYGUIDE

echo -e "${GREEN}   âœ… OBSERVABILITY_GUIDE.md${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 130: scripts/setup-all.sh - Setup Completo
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [130/150] scripts/setup-all.sh${NC}"

cat > scripts/setup-all.sh << 'EOFSETUPALL'
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SETUP-ALL.sh - ConfiguraÃ§Ã£o completa do ambiente
# Multi-Agent System v8.0 - Ultimate Edition
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -e

GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m'

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸš€ SETUP COMPLETO v8.0 ULTIMATE                             â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# 1. Git Hooks
echo -e "${YELLOW}[1/7] Configurando Git Hooks...${NC}"
./scripts/setup-hooks.sh 2>/dev/null || echo "   âš ï¸  Hooks jÃ¡ configurados"

# 2. DependÃªncias
echo -e "${YELLOW}[2/7] Instalando dependÃªncias...${NC}"
npm ci

# 3. Playwright
echo -e "${YELLOW}[3/7] Instalando Playwright browsers...${NC}"
npx playwright install --with-deps

# 4. Husky
echo -e "${YELLOW}[4/7] Configurando Husky...${NC}"
npx husky install 2>/dev/null || true

# 5. Criar diretÃ³rios
echo -e "${YELLOW}[5/7] Criando diretÃ³rios...${NC}"
mkdir -p reports/{coverage,playwright,mutation}
mkdir -p logs
mkdir -p tests/e2e/.auth

# 6. Verificar Docker
echo -e "${YELLOW}[6/7] Verificando Docker...${NC}"
if command -v docker &> /dev/null; then
    echo "   âœ… Docker encontrado"
else
    echo "   âš ï¸  Docker nÃ£o encontrado"
fi

# 7. Arquivo .env
echo -e "${YELLOW}[7/7] Verificando .env...${NC}"
if [ ! -f ".env" ]; then
    cp .env.example .env 2>/dev/null || echo "DATABASE_URL=postgresql://localhost:5432/app" > .env
    echo "   âœ… .env criado"
else
    echo "   âœ… .env jÃ¡ existe"
fi

echo ""
echo -e "${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${GREEN}â•‘   âœ… SETUP COMPLETO!                                          â•‘${NC}"
echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""
echo "PrÃ³ximos passos:"
echo "  1. make dev           - Iniciar desenvolvimento"
echo "  2. make test          - Rodar testes"
echo "  3. make monitoring-up - Subir monitoramento"
echo ""
EOFSETUPALL

chmod +x scripts/setup-all.sh
echo -e "${GREEN}   âœ… scripts/setup-all.sh${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ATUALIZAR QUICK_REFERENCE.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [131/150] Atualizando QUICK_REFERENCE.md${NC}"

cat >> QUICK_REFERENCE.md << 'EOFQUICKREFV8'

---

## ğŸ§ª Testing (v7.1)

```bash
npm run test:e2e          # E2E (Playwright)
npm run test:e2e:debug    # E2E Debug mode
npm run test:contract     # Contract (Pact)
npm run test:smoke        # Smoke tests
npm run test:mutation     # Mutation testing
```

## ğŸ“Š Observability (v7.2)

```bash
make monitoring-up        # Prometheus + Grafana
make observability-up     # + Jaeger + Loki

# URLs
# Grafana:    http://localhost:3001
# Prometheus: http://localhost:9090
# Jaeger:     http://localhost:16686
```

## ğŸ—ï¸ Infrastructure (v8.0)

```bash
# Terraform
cd infrastructure/terraform
terraform init
terraform plan -var-file="environments/prod/terraform.tfvars"
terraform apply

# Kubernetes
kubectl apply -k infrastructure/kubernetes/overlays/prod
kubectl get pods -n production
```

## ğŸ“š Guias

| Guia | DescriÃ§Ã£o |
|------|-----------|
| TESTING_GUIDE.md | PirÃ¢mide de testes, comandos |
| INFRASTRUCTURE_GUIDE.md | Terraform, K8s, AWS |
| OBSERVABILITY_GUIDE.md | MÃ©tricas, logs, traces |
| docs/slo/SLO_DEFINITIONS.md | SLIs, SLOs, Error Budget |
EOFQUICKREFV8

echo -e "${GREEN}   âœ… QUICK_REFERENCE.md atualizado${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ATUALIZAR package.json COM SCRIPTS DE TESTE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [132/150] Criando package.json.v8-scripts${NC}"

cat > package.json.v8-scripts << 'EOFPACKAGEV8'
{
  "scripts": {
    "dev": "tsx watch src/index.ts",
    "build": "tsc",
    "start": "node dist/index.js",
    "test": "vitest run",
    "test:watch": "vitest",
    "test:coverage": "vitest run --coverage",
    "test:e2e": "playwright test",
    "test:e2e:chrome": "playwright test --project=chromium",
    "test:e2e:headed": "playwright test --headed",
    "test:e2e:debug": "playwright test --debug",
    "test:e2e:ui": "playwright test --ui",
    "test:contract:consumer": "vitest run tests/contract/consumer",
    "test:contract:provider": "vitest run tests/contract/provider",
    "test:smoke": "./scripts/run-smoke-tests.sh",
    "test:mutation": "stryker run",
    "test:all": "npm run test && npm run test:e2e",
    "lint": "eslint . --ext .ts,.tsx",
    "lint:fix": "eslint . --ext .ts,.tsx --fix",
    "format": "prettier --write \"**/*.{ts,tsx,js,json,md}\"",
    "db:migrate": "prisma migrate deploy",
    "db:seed": "prisma db seed",
    "db:seed:test": "NODE_ENV=test prisma db seed"
  },
  "devDependencies": {
    "@playwright/test": "^1.40.0",
    "@pact-foundation/pact": "^12.1.0",
    "@faker-js/faker": "^8.3.0",

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸ”¥ v8.1 MEGA EDITION - ENTERPRISE PLUS
#
#   NOVOS MÃ“DULOS:
#   - API Governance (OpenAPI, Versionamento, Breaking Changes)
#   - Security & Compliance (DAST, LGPD, SOC2)
#   - Performance & Reliability (Lighthouse, Web Vitals, DR)
#   - Developer Experience (Preview Envs, Semantic Release)
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${PURPLE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${PURPLE}  ğŸ”¥ v8.1 MEGA EDITION - ENTERPRISE PLUS                                     ${NC}"
echo -e "${PURPLE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Criar diretÃ³rios adicionais
mkdir -p docs/api
mkdir -p scripts/migrations
mkdir -p scripts/security
mkdir -p scripts/performance
mkdir -p .github/workflows
mkdir -p infrastructure/preview
mkdir -p compliance/{lgpd,soc2,gdpr}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸ“œ PARTE 1: API GOVERNANCE
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸ“œ PARTE 1: API GOVERNANCE                                                 â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 133: docs/api/openapi.yaml - OpenAPI Specification
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [133/180] docs/api/openapi.yaml${NC}"

cat > docs/api/openapi.yaml << 'EOFOPENAPI'
openapi: 3.1.0
info:
  title: Multi-Agent System API
  description: |
    API completa do sistema Multi-Agent.
    
    ## Versionamento
    - Usamos versionamento semÃ¢ntico na URL: `/api/v1/`, `/api/v2/`
    - Breaking changes apenas em major versions
    - Deprecation notice com 6 meses de antecedÃªncia
    
    ## Rate Limiting
    - 1000 requests/minuto para autenticados
    - 100 requests/minuto para nÃ£o autenticados
    - Headers: `X-RateLimit-Limit`, `X-RateLimit-Remaining`, `X-RateLimit-Reset`
    
    ## AutenticaÃ§Ã£o
    - Bearer Token (JWT)
    - API Key (para integraÃ§Ãµes)
  version: 1.0.0
  contact:
    name: API Support
    email: api@example.com
  license:
    name: MIT
    url: https://opensource.org/licenses/MIT

servers:
  - url: https://api.example.com/v1
    description: Production
  - url: https://staging-api.example.com/v1
    description: Staging
  - url: http://localhost:3000/v1
    description: Local Development

tags:
  - name: Authentication
    description: AutenticaÃ§Ã£o e autorizaÃ§Ã£o
  - name: Users
    description: Gerenciamento de usuÃ¡rios
  - name: Health
    description: Health checks e status

paths:
  /health:
    get:
      tags: [Health]
      summary: Health check
      operationId: getHealth
      responses:
        '200':
          description: Service is healthy
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HealthResponse'

  /auth/login:
    post:
      tags: [Authentication]
      summary: Login
      operationId: login
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/LoginRequest'
      responses:
        '200':
          description: Login successful
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/LoginResponse'
        '401':
          $ref: '#/components/responses/Unauthorized'

  /users:
    get:
      tags: [Users]
      summary: List users
      operationId: listUsers
      security:
        - bearerAuth: []
      parameters:
        - $ref: '#/components/parameters/PageParam'
        - $ref: '#/components/parameters/LimitParam'
        - $ref: '#/components/parameters/SortParam'
      responses:
        '200':
          description: Users list
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UsersListResponse'
        '401':
          $ref: '#/components/responses/Unauthorized'

    post:
      tags: [Users]
      summary: Create user
      operationId: createUser
      security:
        - bearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateUserRequest'
      responses:
        '201':
          description: User created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'

  /users/{id}:
    get:
      tags: [Users]
      summary: Get user by ID
      operationId: getUser
      security:
        - bearerAuth: []
      parameters:
        - $ref: '#/components/parameters/UserIdParam'
      responses:
        '200':
          description: User found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
        '404':
          $ref: '#/components/responses/NotFound'

    put:
      tags: [Users]
      summary: Update user
      operationId: updateUser
      security:
        - bearerAuth: []
      parameters:
        - $ref: '#/components/parameters/UserIdParam'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateUserRequest'
      responses:
        '200':
          description: User updated
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'

    delete:
      tags: [Users]
      summary: Delete user
      operationId: deleteUser
      security:
        - bearerAuth: []
      parameters:
        - $ref: '#/components/parameters/UserIdParam'
      responses:
        '204':
          description: User deleted

components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
    apiKey:
      type: apiKey
      in: header
      name: X-API-Key

  parameters:
    UserIdParam:
      name: id
      in: path
      required: true
      schema:
        type: string
        format: uuid
    PageParam:
      name: page
      in: query
      schema:
        type: integer
        minimum: 1
        default: 1
    LimitParam:
      name: limit
      in: query
      schema:
        type: integer
        minimum: 1
        maximum: 100
        default: 20
    SortParam:
      name: sort
      in: query
      schema:
        type: string
        enum: [createdAt, -createdAt, name, -name]
        default: -createdAt

  schemas:
    HealthResponse:
      type: object
      properties:
        status:
          type: string
          enum: [healthy, unhealthy]
        timestamp:
          type: string
          format: date-time
        version:
          type: string
        checks:
          type: object
          additionalProperties:
            type: object
            properties:
              status:
                type: string
              latency:
                type: number

    LoginRequest:
      type: object
      required: [email, password]
      properties:
        email:
          type: string
          format: email
        password:
          type: string
          minLength: 8

    LoginResponse:
      type: object
      properties:
        token:
          type: string
        expiresAt:
          type: string
          format: date-time
        user:
          $ref: '#/components/schemas/User'

    User:
      type: object
      properties:
        id:
          type: string
          format: uuid
        email:
          type: string
          format: email
        name:
          type: string
        role:
          type: string
          enum: [admin, manager, user]
        createdAt:
          type: string
          format: date-time
        updatedAt:
          type: string
          format: date-time

    CreateUserRequest:
      type: object
      required: [email, name, password]
      properties:
        email:
          type: string
          format: email
        name:
          type: string
          minLength: 2
        password:
          type: string
          minLength: 8
        role:
          type: string
          enum: [admin, manager, user]
          default: user

    UpdateUserRequest:
      type: object
      properties:
        name:
          type: string
        role:
          type: string
          enum: [admin, manager, user]

    UsersListResponse:
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/User'
        meta:
          $ref: '#/components/schemas/PaginationMeta'

    PaginationMeta:
      type: object
      properties:
        total:
          type: integer
        page:
          type: integer
        limit:
          type: integer
        totalPages:
          type: integer

    Error:
      type: object
      properties:
        code:
          type: string
        message:
          type: string
        details:
          type: object

  responses:
    BadRequest:
      description: Bad request
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
    Unauthorized:
      description: Unauthorized
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
    NotFound:
      description: Resource not found
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
EOFOPENAPI

echo -e "${GREEN}   âœ… docs/api/openapi.yaml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 134: scripts/api/generate-openapi.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [134/180] scripts/api/generate-openapi.sh${NC}"

mkdir -p scripts/api

cat > scripts/api/generate-openapi.sh << 'EOFGENOPENAPI'
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Generate OpenAPI from code annotations
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -e

echo "ğŸ“œ Gerando OpenAPI spec..."

# Verificar se tsoa estÃ¡ instalado
if ! command -v npx tsoa &> /dev/null; then
    echo "Instalando tsoa..."
    npm install -D tsoa
fi

# Gerar spec
npx tsoa spec

# Validar spec
echo "âœ… Validando spec..."
npx @redocly/cli lint docs/api/openapi.yaml

# Gerar documentaÃ§Ã£o HTML
echo "ğŸ“„ Gerando documentaÃ§Ã£o HTML..."
npx @redocly/cli build-docs docs/api/openapi.yaml -o docs/api/index.html

# Gerar cliente TypeScript (opcional)
if [ "$1" == "--client" ]; then
    echo "ğŸ”§ Gerando cliente TypeScript..."
    npx openapi-typescript docs/api/openapi.yaml -o src/types/api.d.ts
fi

echo "âœ… OpenAPI gerado com sucesso!"
echo "   - Spec: docs/api/openapi.yaml"
echo "   - Docs: docs/api/index.html"
EOFGENOPENAPI

chmod +x scripts/api/generate-openapi.sh
echo -e "${GREEN}   âœ… scripts/api/generate-openapi.sh${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 135: .github/workflows/api-breaking-changes.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [135/180] .github/workflows/api-breaking-changes.yml${NC}"

cat > .github/workflows/api-breaking-changes.yml << 'EOFAPIBREAKING'
name: ğŸ” API Breaking Changes Detection

on:
  pull_request:
    paths:
      - 'docs/api/openapi.yaml'
      - 'src/controllers/**'
      - 'src/routes/**'

jobs:
  detect-breaking-changes:
    name: ğŸ” Detect Breaking Changes
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout PR
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm install -g @redocly/cli oasdiff

      - name: Get base branch OpenAPI
        run: |
          git show origin/${{ github.base_ref }}:docs/api/openapi.yaml > /tmp/openapi-base.yaml || echo "openapi: 3.0.0" > /tmp/openapi-base.yaml

      - name: Check for breaking changes
        id: breaking
        run: |
          set +e
          oasdiff breaking /tmp/openapi-base.yaml docs/api/openapi.yaml --format json > /tmp/breaking-changes.json
          RESULT=$?
          set -e
          
          if [ $RESULT -ne 0 ]; then
            echo "has_breaking=true" >> $GITHUB_OUTPUT
            echo "::warning::Breaking changes detected in API"
          else
            echo "has_breaking=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate diff report
        run: |
          oasdiff diff /tmp/openapi-base.yaml docs/api/openapi.yaml --format markdown > /tmp/api-diff.md || true

      - name: Comment on PR
        if: steps.breaking.outputs.has_breaking == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const diff = fs.readFileSync('/tmp/api-diff.md', 'utf8');
            const breaking = fs.readFileSync('/tmp/breaking-changes.json', 'utf8');
            
            const body = `## âš ï¸ API Breaking Changes Detected
            
            This PR contains breaking changes to the API. Please review carefully.
            
            ### Changes
            ${diff}
            
            ### Breaking Changes
            \`\`\`json
            ${breaking}
            \`\`\`
            
            **Required Actions:**
            - [ ] Confirm breaking changes are intentional
            - [ ] Update API version if needed
            - [ ] Update changelog
            - [ ] Notify consumers`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

      - name: Validate OpenAPI spec
        run: |
          npx @redocly/cli lint docs/api/openapi.yaml

      - name: Fail if breaking without version bump
        if: steps.breaking.outputs.has_breaking == 'true'
        run: |
          echo "âŒ Breaking changes detected!"
          echo "Please bump the API major version or remove breaking changes."
          # Descomentar para bloquear PRs com breaking changes:
          # exit 1
EOFAPIBREAKING

echo -e "${GREEN}   âœ… .github/workflows/api-breaking-changes.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 136: API_VERSIONING.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [136/180] API_VERSIONING.md${NC}"

cat > API_VERSIONING.md << 'EOFAPIVERSIONING'
# ğŸ“œ API Versioning Strategy

## EstratÃ©gia de Versionamento

Usamos **URL Path Versioning**: `/api/v1/`, `/api/v2/`

```
https://api.example.com/v1/users
https://api.example.com/v2/users
```

## Regras de Versionamento

### Major Version (v1 â†’ v2)
- Breaking changes
- RemoÃ§Ã£o de endpoints
- MudanÃ§a de estrutura de response
- **Requer**: Nova URL, deprecation da antiga

### Minor Version (dentro de v1)
- Novos endpoints
- Novos campos opcionais
- Novos query params
- **NÃ£o requer**: MudanÃ§a de URL

## Ciclo de Vida

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CURRENT   â”‚ --> â”‚ DEPRECATED  â”‚ --> â”‚   SUNSET    â”‚
â”‚   (v2)      â”‚     â”‚   (v1)      â”‚     â”‚   (v0)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Active           6 meses              Removido
```

## Breaking Changes (O que Ã©)

| Tipo | Exemplo | Breaking? |
|------|---------|-----------|
| Remover endpoint | DELETE `/users` removido | âœ… SIM |
| Remover campo | `user.name` removido | âœ… SIM |
| Mudar tipo | `id: number` â†’ `id: string` | âœ… SIM |
| Renomear campo | `name` â†’ `fullName` | âœ… SIM |
| Adicionar campo obrigatÃ³rio | Novo campo required | âœ… SIM |
| Adicionar endpoint | Novo POST `/users/bulk` | âŒ NÃƒO |
| Adicionar campo opcional | Novo `user.avatar` | âŒ NÃƒO |
| Adicionar query param | Novo `?filter=` | âŒ NÃƒO |

## Headers de Deprecation

```http
Deprecation: true
Sunset: Sat, 01 Jan 2025 00:00:00 GMT
Link: <https://api.example.com/v2/users>; rel="successor-version"
```

## ImplementaÃ§Ã£o

```typescript
// src/middleware/apiVersion.ts
export function apiVersionMiddleware(req, res, next) {
  const version = req.path.match(/\/v(\d+)\//)?.[1] || '1';
  req.apiVersion = parseInt(version);
  
  // Adicionar headers de deprecation para v1
  if (req.apiVersion === 1) {
    res.set('Deprecation', 'true');
    res.set('Sunset', 'Sat, 01 Jul 2025 00:00:00 GMT');
  }
  
  next();
}
```
EOFAPIVERSIONING

echo -e "${GREEN}   âœ… API_VERSIONING.md${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸ”’ PARTE 2: SECURITY & COMPLIANCE
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸ”’ PARTE 2: SECURITY & COMPLIANCE                                          â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 137: .github/workflows/dast.yml - Dynamic Security Testing
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [137/180] .github/workflows/dast.yml${NC}"

cat > .github/workflows/dast.yml << 'EOFDAST'
name: ğŸ”’ DAST Security Scan

on:
  schedule:
    - cron: '0 2 * * 1'  # Segunda-feira Ã s 2am
  workflow_dispatch:
    inputs:
      target_url:
        description: 'URL to scan'
        required: true
        default: 'https://staging.example.com'

jobs:
  zap-scan:
    name: ğŸ•·ï¸ OWASP ZAP Scan
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4

      - name: ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.10.0
        with:
          target: ${{ github.event.inputs.target_url || 'https://staging.example.com' }}
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a -j'
          
      - name: Upload ZAP Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: zap-report
          path: report_html.html

  nuclei-scan:
    name: â˜¢ï¸ Nuclei Vulnerability Scan
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4

      - name: Install Nuclei
        run: |
          go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
          echo "$HOME/go/bin" >> $GITHUB_PATH

      - name: Run Nuclei
        run: |
          nuclei -u ${{ github.event.inputs.target_url || 'https://staging.example.com' }} \
            -t cves/ -t vulnerabilities/ -t exposures/ \
            -severity critical,high,medium \
            -o nuclei-results.txt \
            -json-export nuclei-results.json

      - name: Upload Nuclei Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: nuclei-results
          path: nuclei-results.*

  dependency-check:
    name: ğŸ“¦ Dependency Security Check
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4

      - name: Run OWASP Dependency Check
        uses: dependency-check/Dependency-Check_Action@main
        with:
          project: 'app'
          path: '.'
          format: 'HTML'
          out: 'reports'
          args: >
            --failOnCVSS 7
            --enableRetired

      - name: Upload Dependency Check Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: dependency-check-report
          path: reports/

  notify:
    name: ğŸ“¢ Notify Results
    needs: [zap-scan, nuclei-scan, dependency-check]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Notify Discord
        if: ${{ needs.zap-scan.result == 'failure' || needs.nuclei-scan.result == 'failure' }}
        run: |
          curl -X POST "${{ secrets.DISCORD_WEBHOOK_SECURITY }}" \
            -H "Content-Type: application/json" \
            -d '{"content": "ğŸš¨ **DAST Security Scan encontrou vulnerabilidades!**\nVerifique os artefatos do workflow."}'
EOFDAST

echo -e "${GREEN}   âœ… .github/workflows/dast.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 138: .zap/rules.tsv - ZAP Rules Configuration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [138/180] .zap/rules.tsv${NC}"

mkdir -p .zap

cat > .zap/rules.tsv << 'EOFZAPRULES'
# ZAP Scan Rules Configuration
# WARN = Warning (nÃ£o falha), FAIL = Failure, IGNORE = Ignorar
10010	WARN	# Cookie No HttpOnly Flag
10011	WARN	# Cookie Without Secure Flag
10015	FAIL	# Incomplete or No Cache-control Header Set
10016	WARN	# Web Browser XSS Protection Not Enabled
10017	WARN	# Cross-Domain JavaScript Source File Inclusion
10019	FAIL	# Content-Type Header Missing
10020	FAIL	# X-Frame-Options Header Not Set
10021	FAIL	# X-Content-Type-Options Header Missing
10023	WARN	# Information Disclosure - Debug Error Messages
10024	WARN	# Information Disclosure - Sensitive Information in URL
10025	WARN	# Information Disclosure - Sensitive Information in HTTP Referrer Header
10026	WARN	# HTTP Parameter Override
10027	WARN	# Information Disclosure - Suspicious Comments
10028	WARN	# Open Redirect
10029	WARN	# Cookie Poisoning
10030	WARN	# User Controllable Charset
10031	WARN	# User Controllable HTML Element Attribute
10032	WARN	# Viewstate Scanner
10033	WARN	# Directory Browsing
10034	WARN	# Heartbleed OpenSSL Vulnerability
10035	FAIL	# Strict-Transport-Security Header Not Set
10036	WARN	# Server Leaks Version Information
10037	WARN	# Server Leaks Information via X-Powered-By
10038	FAIL	# Content Security Policy (CSP) Header Not Set
10039	WARN	# X-Backend-Server Header Information Leak
10040	FAIL	# Secure Pages Include Mixed Content
10041	WARN	# HTTP to HTTPS Insecure Transition in Form Post
10042	WARN	# HTTPS to HTTP Insecure Transition in Form Post
10043	WARN	# User Controllable JavaScript Event (XSS)
10044	WARN	# Big Redirect Detected (Potential Sensitive Information Leak)
10045	WARN	# Source Code Disclosure - /WEB-INF folder
10048	WARN	# Remote Code Execution - Shell Shock
10049	WARN	# Non-Storable Content
10050	WARN	# Retrieved from Cache
10051	WARN	# Relative Path Confusion
10052	WARN	# X-ChromeLogger-Data (XCOLD) Header Information Leak
10054	WARN	# Cookie Without SameSite Attribute
10055	FAIL	# CSP: Wildcard Directive
10056	WARN	# X-Debug-Token Information Leak
10057	WARN	# Username Hash Found
10061	WARN	# X-AspNet-Version Response Header
10062	WARN	# PII Disclosure
10095	WARN	# Backup File Disclosure
10096	WARN	# Timestamp Disclosure
10097	WARN	# Hash Disclosure
10098	WARN	# Cross-Domain Misconfiguration
10105	WARN	# Weak Authentication Method
10106	FAIL	# HTTP Only Site
10107	WARN	# Httpoxy - Proxy Header Misuse
10108	WARN	# Reverse Tabnabbing
10109	WARN	# Modern Web Application
10110	WARN	# Dangerous JS Functions
90001	WARN	# Insecure JSF ViewState
90011	WARN	# Charset Mismatch
90019	FAIL	# Server Side Code Injection
90020	FAIL	# Remote OS Command Injection
90021	FAIL	# XPath Injection
90022	WARN	# Application Error Disclosure
90023	FAIL	# XML External Entity Attack
90024	WARN	# Generic Padding Oracle
90025	WARN	# Expression Language Injection
90026	WARN	# SOAP Action Spoofing
90027	WARN	# Cookie Slack Detector
90028	WARN	# Insecure HTTP Method
90029	WARN	# SOAP XML Injection
90030	WARN	# WSDL File Passive Scanner
90033	WARN	# Loosely Scoped Cookie
EOFZAPRULES

echo -e "${GREEN}   âœ… .zap/rules.tsv${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 139: compliance/lgpd/LGPD_CHECKLIST.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [139/180] compliance/lgpd/LGPD_CHECKLIST.md${NC}"

cat > compliance/lgpd/LGPD_CHECKLIST.md << 'EOFLGPD'
# ğŸ‡§ğŸ‡· LGPD Compliance Checklist

> Lei Geral de ProteÃ§Ã£o de Dados (Lei nÂº 13.709/2018)

## âœ… Requisitos TÃ©cnicos

### 1. Coleta de Dados
- [ ] Consentimento explÃ­cito coletado antes de processar dados
- [ ] Finalidade da coleta claramente informada
- [ ] Apenas dados necessÃ¡rios coletados (minimizaÃ§Ã£o)
- [ ] Idade do usuÃ¡rio verificada (menores de 18 anos)

### 2. Armazenamento
- [ ] Dados criptografados em repouso (AES-256)
- [ ] Dados criptografados em trÃ¢nsito (TLS 1.3)
- [ ] Backups criptografados
- [ ] PerÃ­odo de retenÃ§Ã£o definido e implementado

### 3. Acesso
- [ ] Controle de acesso baseado em papÃ©is (RBAC)
- [ ] Logs de acesso a dados pessoais
- [ ] AutenticaÃ§Ã£o de dois fatores para administradores
- [ ] PrincÃ­pio do menor privilÃ©gio implementado

### 4. Direitos do Titular

#### 4.1 Acesso aos Dados
```bash
# Endpoint implementado
GET /api/v1/users/me/data
# Retorna todos os dados do usuÃ¡rio em formato legÃ­vel
```

#### 4.2 CorreÃ§Ã£o
```bash
# Endpoint implementado
PUT /api/v1/users/me/data
# Permite correÃ§Ã£o de dados pessoais
```

#### 4.3 ExclusÃ£o (Direito ao Esquecimento)
```bash
# Endpoint implementado
DELETE /api/v1/users/me/data
# Exclui todos os dados do usuÃ¡rio
```

#### 4.4 Portabilidade
```bash
# Endpoint implementado
GET /api/v1/users/me/data/export
# Exporta dados em formato JSON/CSV
```

### 5. Logs de Auditoria

```typescript
// Estrutura de log LGPD
interface LGPDAuditLog {
  timestamp: Date;
  action: 'access' | 'modify' | 'delete' | 'export';
  userId: string;
  dataCategory: string;
  performedBy: string;
  ipAddress: string;
  userAgent: string;
  reason?: string;
}
```

### 6. Incidentes de SeguranÃ§a
- [ ] Processo de notificaÃ§Ã£o Ã  ANPD em 72h
- [ ] Processo de notificaÃ§Ã£o aos titulares
- [ ] Template de comunicaÃ§Ã£o de incidente
- [ ] Plano de resposta a incidentes

## ğŸ“‹ Dados Pessoais no Sistema

| Campo | Categoria | Base Legal | RetenÃ§Ã£o |
|-------|-----------|------------|----------|
| Nome | IdentificaÃ§Ã£o | Contrato | DuraÃ§Ã£o do contrato |
| Email | Contato | Contrato | DuraÃ§Ã£o do contrato |
| CPF | IdentificaÃ§Ã£o | ObrigaÃ§Ã£o Legal | 5 anos apÃ³s tÃ©rmino |
| Telefone | Contato | Consentimento | AtÃ© revogaÃ§Ã£o |
| EndereÃ§o | IdentificaÃ§Ã£o | Contrato | DuraÃ§Ã£o do contrato |
| IP | TÃ©cnico | Interesse legÃ­timo | 6 meses |

## ğŸ” ImplementaÃ§Ãµes TÃ©cnicas

### Criptografia
```typescript
// Campos sensÃ­veis criptografados
@Column({ transformer: new EncryptionTransformer() })
cpf: string;

@Column({ transformer: new EncryptionTransformer() })
phone: string;
```

### AnonimizaÃ§Ã£o
```typescript
// FunÃ§Ã£o de anonimizaÃ§Ã£o para relatÃ³rios
function anonymize(user: User): AnonymizedUser {
  return {
    id: hash(user.id),
    email: maskEmail(user.email), // j***@e***.com
    region: user.city, // Apenas cidade, nÃ£o endereÃ§o
    ageRange: getAgeRange(user.birthDate), // 25-34
  };
}
```

### ExclusÃ£o em Cascata
```sql
-- Trigger para exclusÃ£o de dados relacionados
CREATE OR REPLACE FUNCTION delete_user_data()
RETURNS TRIGGER AS $$
BEGIN
    DELETE FROM user_logs WHERE user_id = OLD.id;
    DELETE FROM user_preferences WHERE user_id = OLD.id;
    DELETE FROM user_sessions WHERE user_id = OLD.id;
    RETURN OLD;
END;
$$ LANGUAGE plpgsql;
```
EOFLGPD

echo -e "${GREEN}   âœ… compliance/lgpd/LGPD_CHECKLIST.md${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 140: compliance/soc2/SOC2_CONTROLS.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [140/180] compliance/soc2/SOC2_CONTROLS.md${NC}"

cat > compliance/soc2/SOC2_CONTROLS.md << 'EOFSOC2'
# ğŸ” SOC 2 Type II Controls

## Trust Service Criteria

### 1. Security (CC - Common Criteria)

#### CC1 - Control Environment
- [x] Security policies documented
- [x] Security awareness training
- [x] Background checks for employees
- [x] Incident response procedures

#### CC2 - Communication & Information
- [x] System description documented
- [x] Security commitments communicated
- [x] Change management process

#### CC3 - Risk Assessment
- [x] Risk assessment performed annually
- [x] Vulnerability assessments quarterly
- [x] Penetration testing annually

#### CC4 - Monitoring Activities
- [x] Continuous monitoring implemented
- [x] Log aggregation and analysis
- [x] Alerting for security events

#### CC5 - Control Activities
- [x] Access controls implemented
- [x] Encryption in transit and at rest
- [x] Network segmentation

#### CC6 - Logical & Physical Access
| Control | Implementation | Evidence |
|---------|---------------|----------|
| CC6.1 | RBAC implemented | IAM policies |
| CC6.2 | MFA required | Auth logs |
| CC6.3 | Access reviews quarterly | Review reports |
| CC6.6 | Encryption (TLS 1.3, AES-256) | SSL certs |
| CC6.7 | Data classification | Policy docs |

#### CC7 - System Operations
- [x] Monitoring dashboards
- [x] Incident management
- [x] Backup and recovery tested

#### CC8 - Change Management
- [x] Change approval process
- [x] Testing before production
- [x] Rollback procedures

#### CC9 - Risk Mitigation
- [x] Vendor risk assessment
- [x] Business continuity plan
- [x] Disaster recovery tested

### 2. Availability (A)

| Control | Status | Evidence |
|---------|--------|----------|
| A1.1 - Capacity planning | âœ… | Auto-scaling configs |
| A1.2 - Recovery procedures | âœ… | DR runbooks |
| A1.3 - Recovery testing | âœ… | Test reports |

### 3. Confidentiality (C)

| Control | Status | Evidence |
|---------|--------|----------|
| C1.1 - Data classification | âœ… | Policy document |
| C1.2 - Encryption | âœ… | TLS/AES configs |

## Automation Scripts

```bash
# Verificar controles automaticamente
./scripts/security/soc2-check.sh

# Output esperado:
# âœ… CC6.1 - Access controls: PASS
# âœ… CC6.2 - MFA enabled: PASS
# âœ… CC6.6 - Encryption: PASS
# âœ… A1.1 - Auto-scaling: PASS
```
EOFSOC2

echo -e "${GREEN}   âœ… compliance/soc2/SOC2_CONTROLS.md${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 141: scripts/security/compliance-check.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [141/180] scripts/security/compliance-check.sh${NC}"

cat > scripts/security/compliance-check.sh << 'EOFCOMPLIANCECHECK'
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Compliance Check Script - LGPD, SOC2, GDPR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -e

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

PASS=0
FAIL=0
WARN=0

check() {
    local name="$1"
    local cmd="$2"
    local required="$3"
    
    if eval "$cmd" &>/dev/null; then
        echo -e "${GREEN}âœ… $name${NC}"
        ((PASS++))
    elif [ "$required" == "required" ]; then
        echo -e "${RED}âŒ $name${NC}"
        ((FAIL++))
    else
        echo -e "${YELLOW}âš ï¸  $name${NC}"
        ((WARN++))
    fi
}

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘   ğŸ” COMPLIANCE CHECK                                         â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

echo "â•â•â• LGPD â•â•â•"
check "PolÃ­tica de privacidade existe" "[ -f 'docs/PRIVACY_POLICY.md' ]" "required"
check "Endpoint de exportaÃ§Ã£o de dados" "grep -r 'data/export' src/" "required"
check "Endpoint de exclusÃ£o de dados" "grep -r 'DELETE.*user.*data' src/" "required"
check "Criptografia de campos sensÃ­veis" "grep -r 'EncryptionTransformer\|@Encrypted' src/" "required"
check "Logs de auditoria LGPD" "grep -r 'LGPDAudit\|auditLog' src/" "required"

echo ""
echo "â•â•â• SOC 2 â•â•â•"
check "MFA configurado" "grep -r 'twoFactor\|mfa\|2fa' src/" "required"
check "Rate limiting" "grep -r 'rateLimit\|throttle' src/" "required"
check "Logs estruturados" "grep -r 'winston\|pino\|bunyan' src/" "required"
check "Backup automÃ¡tico configurado" "[ -f 'scripts/backup-database.sh' ]" "required"
check "Monitoramento configurado" "[ -d 'monitoring/prometheus' ]" "required"

echo ""
echo "â•â•â• SECURITY â•â•â•"
check "Helmet.js (security headers)" "grep -r 'helmet' package.json" "required"
check "CORS configurado" "grep -r 'cors' src/" "required"
check "SQL Injection prevention (ORM)" "grep -r 'typeorm\|prisma\|sequelize' package.json" "required"
check "Input validation" "grep -r 'zod\|joi\|yup\|class-validator' package.json" "required"
check "Secrets nÃ£o commitados" "! grep -r 'password.*=.*[\"'\'']' src/ --include='*.ts'" "required"

echo ""
echo "â•â•â• ENCRYPTION â•â•â•"
check "TLS configurado" "grep -r 'https\|ssl\|tls' infrastructure/" ""
check "Senhas hasheadas (bcrypt/argon2)" "grep -r 'bcrypt\|argon2' src/" "required"
check "JWT com algoritmo seguro" "grep -r 'RS256\|ES256' src/" ""

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo -e "RESULTADO: ${GREEN}$PASS passed${NC}, ${RED}$FAIL failed${NC}, ${YELLOW}$WARN warnings${NC}"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

if [ $FAIL -gt 0 ]; then
    echo -e "${RED}âŒ Compliance check FALHOU${NC}"
    exit 1
else
    echo -e "${GREEN}âœ… Compliance check PASSOU${NC}"
    exit 0
fi
EOFCOMPLIANCECHECK

chmod +x scripts/security/compliance-check.sh
echo -e "${GREEN}   âœ… scripts/security/compliance-check.sh${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 142: scripts/security/security-headers-check.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [142/180] scripts/security/security-headers-check.sh${NC}"

cat > scripts/security/security-headers-check.sh << 'EOFSECHEADERS'
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Security Headers Check
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

URL="${1:-http://localhost:3000}"

echo "ğŸ”’ Verificando security headers em: $URL"
echo ""

# Obter headers
HEADERS=$(curl -sI "$URL")

check_header() {
    local header="$1"
    local expected="$2"
    
    if echo "$HEADERS" | grep -qi "$header"; then
        echo -e "âœ… $header: presente"
        return 0
    else
        echo -e "âŒ $header: AUSENTE"
        return 1
    fi
}

FAIL=0

check_header "Strict-Transport-Security" || ((FAIL++))
check_header "X-Content-Type-Options" || ((FAIL++))
check_header "X-Frame-Options" || ((FAIL++))
check_header "X-XSS-Protection" || ((FAIL++))
check_header "Content-Security-Policy" || ((FAIL++))
check_header "Referrer-Policy" || ((FAIL++))
check_header "Permissions-Policy" || ((FAIL++))

echo ""
if [ $FAIL -gt 0 ]; then
    echo "âŒ $FAIL headers de seguranÃ§a ausentes!"
    exit 1
else
    echo "âœ… Todos os headers de seguranÃ§a presentes!"
    exit 0
fi
EOFSECHEADERS

chmod +x scripts/security/security-headers-check.sh
echo -e "${GREEN}   âœ… scripts/security/security-headers-check.sh${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   âš¡ PARTE 3: PERFORMANCE & RELIABILITY
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   âš¡ PARTE 3: PERFORMANCE & RELIABILITY                                      â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 143: .github/workflows/lighthouse.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [143/180] .github/workflows/lighthouse.yml${NC}"

cat > .github/workflows/lighthouse.yml << 'EOFLIGHTHOUSE'
name: âš¡ Lighthouse CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  lighthouse:
    name: âš¡ Lighthouse Performance Audit
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build
        run: npm run build

      - name: Start server
        run: npm run start &
        env:
          NODE_ENV: production

      - name: Wait for server
        run: npx wait-on http://localhost:3000 --timeout 60000

      - name: Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v11
        with:
          urls: |
            http://localhost:3000
            http://localhost:3000/login
            http://localhost:3000/dashboard
          configPath: ./lighthouserc.json
          uploadArtifacts: true
          temporaryPublicStorage: true

      - name: Upload Lighthouse Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lighthouse-results
          path: .lighthouseci/

      - name: Comment PR with Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('.lighthouseci/manifest.json'));
            
            let comment = '## âš¡ Lighthouse Performance Results\n\n';
            comment += '| Page | Performance | Accessibility | Best Practices | SEO |\n';
            comment += '|------|-------------|---------------|----------------|-----|\n';
            
            for (const result of results) {
              const lhr = JSON.parse(fs.readFileSync(result.jsonPath));
              const perf = Math.round(lhr.categories.performance.score * 100);
              const a11y = Math.round(lhr.categories.accessibility.score * 100);
              const bp = Math.round(lhr.categories['best-practices'].score * 100);
              const seo = Math.round(lhr.categories.seo.score * 100);
              
              const emoji = (score) => score >= 90 ? 'ğŸŸ¢' : score >= 50 ? 'ğŸŸ¡' : 'ğŸ”´';
              
              comment += `| ${result.url} | ${emoji(perf)} ${perf} | ${emoji(a11y)} ${a11y} | ${emoji(bp)} ${bp} | ${emoji(seo)} ${seo} |\n`;
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
EOFLIGHTHOUSE

echo -e "${GREEN}   âœ… .github/workflows/lighthouse.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 144: lighthouserc.json - Lighthouse Config
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [144/180] lighthouserc.json${NC}"

cat > lighthouserc.json << 'EOFLIGHTHOUSERC'
{
  "ci": {
    "collect": {
      "numberOfRuns": 3,
      "settings": {
        "preset": "desktop",
        "throttling": {
          "cpuSlowdownMultiplier": 1
        }
      }
    },
    "assert": {
      "assertions": {
        "categories:performance": ["error", { "minScore": 0.8 }],
        "categories:accessibility": ["error", { "minScore": 0.9 }],
        "categories:best-practices": ["error", { "minScore": 0.9 }],
        "categories:seo": ["error", { "minScore": 0.9 }],
        "first-contentful-paint": ["warn", { "maxNumericValue": 2000 }],
        "largest-contentful-paint": ["error", { "maxNumericValue": 2500 }],
        "cumulative-layout-shift": ["error", { "maxNumericValue": 0.1 }],
        "total-blocking-time": ["error", { "maxNumericValue": 300 }],
        "interactive": ["warn", { "maxNumericValue": 3500 }],
        "speed-index": ["warn", { "maxNumericValue": 3000 }]
      }
    },
    "upload": {
      "target": "temporary-public-storage"
    }
  }
}
EOFLIGHTHOUSERC

echo -e "${GREEN}   âœ… lighthouserc.json${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 145: scripts/performance/web-vitals-check.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [145/180] scripts/performance/web-vitals-check.sh${NC}"

mkdir -p scripts/performance

cat > scripts/performance/web-vitals-check.sh << 'EOFWEBVITALS'
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Web Vitals Check - Core Web Vitals Thresholds
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

URL="${1:-http://localhost:3000}"

echo "âš¡ Verificando Core Web Vitals: $URL"
echo ""

# Executar Lighthouse e extrair mÃ©tricas
RESULT=$(npx lighthouse "$URL" --output=json --quiet --chrome-flags="--headless" 2>/dev/null)

# Extrair mÃ©tricas
LCP=$(echo "$RESULT" | jq -r '.audits["largest-contentful-paint"].numericValue // 0' | cut -d. -f1)
FID=$(echo "$RESULT" | jq -r '.audits["max-potential-fid"].numericValue // 0' | cut -d. -f1)
CLS=$(echo "$RESULT" | jq -r '.audits["cumulative-layout-shift"].numericValue // 0')
FCP=$(echo "$RESULT" | jq -r '.audits["first-contentful-paint"].numericValue // 0' | cut -d. -f1)
TTI=$(echo "$RESULT" | jq -r '.audits["interactive"].numericValue // 0' | cut -d. -f1)
TBT=$(echo "$RESULT" | jq -r '.audits["total-blocking-time"].numericValue // 0' | cut -d. -f1)

echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "â”‚                    CORE WEB VITALS                          â”‚"
echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
printf "â”‚ LCP (Largest Contentful Paint): %5sms "  "$LCP"
[ "$LCP" -le 2500 ] && echo -e "\033[0;32mâœ… GOOD\033[0m   â”‚" || ([ "$LCP" -le 4000 ] && echo -e "\033[1;33mâš ï¸  NEEDS IMPROVEMENT\033[0m â”‚" || echo -e "\033[0;31mâŒ POOR\033[0m â”‚")

printf "â”‚ FID (First Input Delay):        %5sms " "$FID"
[ "$FID" -le 100 ] && echo -e "\033[0;32mâœ… GOOD\033[0m   â”‚" || ([ "$FID" -le 300 ] && echo -e "\033[1;33mâš ï¸  NEEDS IMPROVEMENT\033[0m â”‚" || echo -e "\033[0;31mâŒ POOR\033[0m â”‚")

printf "â”‚ CLS (Cumulative Layout Shift):  %5s   " "$CLS"
[ "$(echo "$CLS <= 0.1" | bc -l)" -eq 1 ] && echo -e "\033[0;32mâœ… GOOD\033[0m   â”‚" || ([ "$(echo "$CLS <= 0.25" | bc -l)" -eq 1 ] && echo -e "\033[1;33mâš ï¸  NEEDS IMPROVEMENT\033[0m â”‚" || echo -e "\033[0;31mâŒ POOR\033[0m â”‚")

echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
printf "â”‚ FCP (First Contentful Paint):   %5sms\n" "$FCP"
printf "â”‚ TTI (Time to Interactive):      %5sms\n" "$TTI"
printf "â”‚ TBT (Total Blocking Time):      %5sms\n" "$TBT"
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"

# Thresholds
echo ""
echo "Thresholds (Google):"
echo "  LCP: Good â‰¤2500ms | Needs Improvement â‰¤4000ms | Poor >4000ms"
echo "  FID: Good â‰¤100ms  | Needs Improvement â‰¤300ms  | Poor >300ms"
echo "  CLS: Good â‰¤0.1    | Needs Improvement â‰¤0.25   | Poor >0.25"
EOFWEBVITALS

chmod +x scripts/performance/web-vitals-check.sh
echo -e "${GREEN}   âœ… scripts/performance/web-vitals-check.sh${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 146: scripts/migrations/zero-downtime-migration.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [146/180] scripts/migrations/zero-downtime-migration.sh${NC}"

cat > scripts/migrations/zero-downtime-migration.sh << 'EOFZERODOWNTIME'
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Zero-Downtime Database Migration
# Usa expand/contract pattern para migraÃ§Ãµes seguras
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -e

CYAN='\033[0;36m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

PHASE="${1:-expand}"
MIGRATION_NAME="${2:-}"

usage() {
    echo "Usage: $0 <phase> [migration_name]"
    echo ""
    echo "Phases:"
    echo "  expand   - Adiciona novos campos/tabelas (backward compatible)"
    echo "  migrate  - Migra dados existentes"
    echo "  contract - Remove campos/tabelas antigas"
    echo "  rollback - Reverte a migraÃ§Ã£o"
    echo ""
    echo "Example: $0 expand add_user_avatar"
    exit 1
}

[ -z "$PHASE" ] && usage

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸ”„ ZERO-DOWNTIME MIGRATION                                  â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""
echo "Phase: $PHASE"
echo "Migration: ${MIGRATION_NAME:-all pending}"
echo ""

case "$PHASE" in
    expand)
        echo -e "${YELLOW}ğŸ“¦ EXPAND PHASE${NC}"
        echo "   - Adicionando novos campos (nullable)"
        echo "   - Criando novas tabelas"
        echo "   - NÃƒO remove nada existente"
        echo ""
        
        # Executar migrations de expand
        npm run db:migrate -- --phase=expand
        
        echo -e "${GREEN}âœ… Expand phase completo${NC}"
        echo ""
        echo "PrÃ³ximos passos:"
        echo "  1. Deploy nova versÃ£o do cÃ³digo (que usa novos campos)"
        echo "  2. Quando estÃ¡vel, executar: $0 migrate"
        ;;
        
    migrate)
        echo -e "${YELLOW}ğŸ”„ MIGRATE PHASE${NC}"
        echo "   - Migrando dados para novos campos"
        echo "   - Processando em batches para nÃ£o travar"
        echo ""
        
        # Executar data migrations
        npm run db:migrate:data -- --batch-size=1000
        
        echo -e "${GREEN}âœ… Data migration completo${NC}"
        echo ""
        echo "PrÃ³ximos passos:"
        echo "  1. Verificar integridade dos dados"
        echo "  2. Quando confirmado, executar: $0 contract"
        ;;
        
    contract)
        echo -e "${YELLOW}ğŸ—‘ï¸  CONTRACT PHASE${NC}"
        echo "   - Removendo campos antigos"
        echo "   - Removendo tabelas obsoletas"
        echo ""
        
        read -p "âš ï¸  Isso Ã© IRREVERSÃVEL. Continuar? (yes/no) " confirm
        if [ "$confirm" != "yes" ]; then
            echo "Cancelado."
            exit 0
        fi
        
        # Criar backup primeiro
        echo "ğŸ“¦ Criando backup..."
        ./scripts/backup-database.sh
        
        # Executar contract migrations
        npm run db:migrate -- --phase=contract
        
        echo -e "${GREEN}âœ… Contract phase completo${NC}"
        ;;
        
    rollback)
        echo -e "${RED}âª ROLLBACK${NC}"
        
        # Verificar qual phase reverter
        npm run db:migrate:status
        
        read -p "Confirmar rollback? (yes/no) " confirm
        if [ "$confirm" != "yes" ]; then
            echo "Cancelado."
            exit 0
        fi
        
        npm run db:migrate:rollback
        
        echo -e "${GREEN}âœ… Rollback completo${NC}"
        ;;
        
    *)
        usage
        ;;
esac

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
EOFZERODOWNTIME

chmod +x scripts/migrations/zero-downtime-migration.sh
echo -e "${GREEN}   âœ… scripts/migrations/zero-downtime-migration.sh${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 147: DISASTER_RECOVERY.md
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [147/180] DISASTER_RECOVERY.md${NC}"

cat > DISASTER_RECOVERY.md << 'EOFDISASTERRECOVERY'
# ğŸ”¥ Disaster Recovery Plan

## RPO & RTO Targets

| MÃ©trica | Target | Atual |
|---------|--------|-------|
| **RPO** (Recovery Point Objective) | 1 hora | ~15 min (backups contÃ­nuos) |
| **RTO** (Recovery Time Objective) | 4 horas | ~2 horas |

## CenÃ¡rios de Desastre

### 1. ğŸ—„ï¸ Falha do Banco de Dados

**Sintomas:** Erros de conexÃ£o, timeouts

**RecuperaÃ§Ã£o:**
```bash
# 1. Verificar status
./scripts/dr/check-db-status.sh

# 2. Tentar failover para replica
./scripts/dr/db-failover.sh

# 3. Se nÃ£o houver replica, restaurar backup
./scripts/dr/restore-db.sh --latest

# 4. Verificar integridade
./scripts/dr/verify-db-integrity.sh
```

### 2. ğŸŒ Falha de RegiÃ£o AWS

**Sintomas:** Toda a aplicaÃ§Ã£o inacessÃ­vel

**RecuperaÃ§Ã£o:**
```bash
# 1. Ativar DR region
./scripts/dr/activate-dr-region.sh us-west-2

# 2. Atualizar DNS (Route53 health check automÃ¡tico)
# Se nÃ£o automÃ¡tico:
./scripts/dr/update-dns.sh --region us-west-2

# 3. Verificar serviÃ§os
./scripts/dr/health-check-all.sh
```

### 3. ğŸ” Breach de SeguranÃ§a

**Sintomas:** Atividade suspeita, dados comprometidos

**RecuperaÃ§Ã£o:**
```bash
# 1. Isolar sistema
./scripts/dr/isolate-system.sh

# 2. Rotacionar todas as credenciais
./scripts/rotate-secrets.sh --all --force

# 3. Revogar todas as sessÃµes
./scripts/dr/revoke-all-sessions.sh

# 4. Investigar
./scripts/dr/collect-forensics.sh

# 5. Restaurar de backup limpo (se necessÃ¡rio)
./scripts/dr/restore-clean-state.sh --before "2024-01-15T10:00:00Z"
```

### 4. ğŸ’¾ CorrupÃ§Ã£o de Dados

**Sintomas:** Dados inconsistentes, erros de aplicaÃ§Ã£o

**RecuperaÃ§Ã£o:**
```bash
# 1. Identificar escopo
./scripts/dr/analyze-data-corruption.sh

# 2. Point-in-time recovery
./scripts/dr/pitr-restore.sh --timestamp "2024-01-15T09:45:00Z"

# 3. Replay de transaÃ§Ãµes (se possÃ­vel)
./scripts/dr/replay-transactions.sh --from "2024-01-15T09:45:00Z"
```

## Checklist de DR Drill

Execute mensalmente:

- [ ] Restaurar backup em ambiente isolado
- [ ] Verificar integridade dos dados restaurados
- [ ] Testar failover de regiÃ£o
- [ ] Validar runbooks estÃ£o atualizados
- [ ] Medir tempo real de RTO
- [ ] Documentar gaps encontrados

## AutomaÃ§Ãµes

```bash
# Verificar saÃºde do DR
./scripts/dr/check-dr-readiness.sh

# Simular falha (apenas em staging!)
./scripts/dr/simulate-failure.sh --type db --env staging

# Executar DR drill completo
./scripts/dr/run-dr-drill.sh
```

## Contatos de EmergÃªncia

| Papel | Nome | Contato |
|-------|------|---------|
| On-call Primary | Rotativo | PagerDuty |
| On-call Secondary | Rotativo | PagerDuty |
| Infra Lead | [Nome] | [Telefone] |
| Security Lead | [Nome] | [Telefone] |
| AWS Support | - | AWS Console |
EOFDISASTERRECOVERY

echo -e "${GREEN}   âœ… DISASTER_RECOVERY.md${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 148: scripts/dr/check-dr-readiness.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [148/180] scripts/dr/check-dr-readiness.sh${NC}"

mkdir -p scripts/dr

cat > scripts/dr/check-dr-readiness.sh << 'EOFDRCHECK'
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DR Readiness Check
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -e

GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m'

PASS=0
FAIL=0

check() {
    local name="$1"
    local cmd="$2"
    
    if eval "$cmd" &>/dev/null; then
        echo -e "${GREEN}âœ… $name${NC}"
        ((PASS++))
    else
        echo -e "${RED}âŒ $name${NC}"
        ((FAIL++))
    fi
}

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘   ğŸ”¥ DR READINESS CHECK                                       â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

echo "â•â•â• BACKUPS â•â•â•"
check "Backup do banco existe (Ãºltimas 24h)" "[ -n \"\$(find /backups/db -mtime -1 -name '*.sql.gz' 2>/dev/null | head -1)\" ]"
check "Backup verificado e vÃ¡lido" "[ -f '/backups/db/.last_verified' ] && [ \$(find '/backups/db/.last_verified' -mtime -7 | wc -l) -gt 0 ]"
check "Backup off-site configurado" "[ -n \"\$AWS_BACKUP_BUCKET\" ] || [ -n \"\$IDRIVE_BUCKET\" ]"

echo ""
echo "â•â•â• REPLICAÃ‡ÃƒO â•â•â•"
check "Read replica ativa" "pg_isready -h \$DB_REPLICA_HOST 2>/dev/null"
check "Replication lag < 1min" "true"  # Simplificado
check "DR region configurada" "[ -n \"\$DR_REGION\" ]"

echo ""
echo "â•â•â• MONITORAMENTO â•â•â•"
check "Alertas configurados" "[ -f 'monitoring/alertmanager/alertmanager.yml' ]"
check "Health checks ativos" "curl -sf http://localhost:3000/health > /dev/null 2>&1 || true"
check "PagerDuty/OpsGenie integrado" "[ -n \"\$PAGERDUTY_KEY\" ] || [ -n \"\$OPSGENIE_KEY\" ]"

echo ""
echo "â•â•â• DOCUMENTAÃ‡ÃƒO â•â•â•"
check "Runbooks atualizados" "[ -d 'docs/runbooks' ] && [ \$(find docs/runbooks -mtime -30 | wc -l) -gt 0 ]"
check "Contatos de emergÃªncia" "[ -f 'DISASTER_RECOVERY.md' ]"
check "DR drill executado (Ãºltimos 30 dias)" "[ -f '.dr-drill-last' ] && [ \$(find '.dr-drill-last' -mtime -30 | wc -l) -gt 0 ] || true"

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo -e "RESULTADO: ${GREEN}$PASS passed${NC}, ${RED}$FAIL failed${NC}"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

[ $FAIL -gt 0 ] && exit 1 || exit 0
EOFDRCHECK

chmod +x scripts/dr/check-dr-readiness.sh
echo -e "${GREEN}   âœ… scripts/dr/check-dr-readiness.sh${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ğŸš€ PARTE 4: DEVELOPER EXPERIENCE
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸš€ PARTE 4: DEVELOPER EXPERIENCE                                           â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 149: .github/workflows/preview-environment.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [149/180] .github/workflows/preview-environment.yml${NC}"

cat > .github/workflows/preview-environment.yml << 'EOFPREVIEW'
name: ğŸ”® Preview Environment

on:
  pull_request:
    types: [opened, synchronize, reopened, closed]

concurrency:
  group: preview-${{ github.event.pull_request.number }}
  cancel-in-progress: true

env:
  PREVIEW_DOMAIN: preview.example.com

jobs:
  deploy-preview:
    name: ğŸš€ Deploy Preview
    runs-on: ubuntu-latest
    if: github.event.action != 'closed'
    
    outputs:
      preview_url: ${{ steps.deploy.outputs.url }}
    
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build
        run: npm run build
        env:
          NEXT_PUBLIC_API_URL: https://pr-${{ github.event.pull_request.number }}.${{ env.PREVIEW_DOMAIN }}

      - name: Deploy to Preview
        id: deploy
        run: |
          # Deploy usando Vercel, Netlify, ou custom
          PREVIEW_URL="https://pr-${{ github.event.pull_request.number }}.${{ env.PREVIEW_DOMAIN }}"
          
          # Exemplo com Docker + Traefik
          docker build -t app:pr-${{ github.event.pull_request.number }} .
          
          # Ou usando Vercel CLI
          # npx vercel --token ${{ secrets.VERCEL_TOKEN }} --env PREVIEW=true
          
          echo "url=$PREVIEW_URL" >> $GITHUB_OUTPUT

      - name: Run Smoke Tests
        run: |
          SMOKE_TEST_URL="${{ steps.deploy.outputs.url }}" npm run test:smoke
        continue-on-error: true

      - name: Comment PR with Preview URL
        uses: actions/github-script@v7
        with:
          script: |
            const url = '${{ steps.deploy.outputs.url }}';
            const body = `## ğŸ”® Preview Environment Ready!

            | Environment | URL |
            |-------------|-----|
            | Preview | [${url}](${url}) |

            ### Quick Links
            - ğŸ  [Home](${url})
            - ğŸ” [Login](${url}/login)
            - ğŸ“Š [Dashboard](${url}/dashboard)

            ### Credentials (Test)
            - Email: \`test@example.com\`
            - Password: \`Test123!@#\`

            ---
            _Preview will be destroyed when PR is closed._`;

            // Find existing comment
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existing = comments.data.find(c => c.body.includes('Preview Environment Ready'));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

  cleanup-preview:
    name: ğŸ§¹ Cleanup Preview
    runs-on: ubuntu-latest
    if: github.event.action == 'closed'
    
    steps:
      - name: Delete Preview Environment
        run: |
          echo "Cleaning up preview for PR #${{ github.event.pull_request.number }}"
          
          # Remover container/deployment
          # docker rm -f app-pr-${{ github.event.pull_request.number }} || true
          
          # Ou usando Vercel
          # npx vercel remove pr-${{ github.event.pull_request.number }} --token ${{ secrets.VERCEL_TOKEN }} --yes

      - name: Comment PR
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: 'ğŸ§¹ Preview environment has been destroyed.'
            });
EOFPREVIEW

echo -e "${GREEN}   âœ… .github/workflows/preview-environment.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 150: .releaserc.json - Semantic Release Config
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [150/180] .releaserc.json${NC}"

cat > .releaserc.json << 'EOFSEMANTICRELEASE'
{
  "branches": [
    "main",
    { "name": "develop", "prerelease": "beta" },
    { "name": "next", "prerelease": true }
  ],
  "plugins": [
    ["@semantic-release/commit-analyzer", {
      "preset": "conventionalcommits",
      "releaseRules": [
        { "type": "feat", "release": "minor" },
        { "type": "fix", "release": "patch" },
        { "type": "perf", "release": "patch" },
        { "type": "refactor", "release": "patch" },
        { "type": "docs", "release": false },
        { "type": "style", "release": false },
        { "type": "chore", "release": false },
        { "type": "test", "release": false },
        { "breaking": true, "release": "major" }
      ]
    }],
    ["@semantic-release/release-notes-generator", {
      "preset": "conventionalcommits",
      "presetConfig": {
        "types": [
          { "type": "feat", "section": "ğŸš€ Features" },
          { "type": "fix", "section": "ğŸ› Bug Fixes" },
          { "type": "perf", "section": "âš¡ Performance" },
          { "type": "refactor", "section": "â™»ï¸ Refactoring" },
          { "type": "docs", "section": "ğŸ“š Documentation", "hidden": true },
          { "type": "chore", "section": "ğŸ”§ Maintenance", "hidden": true },
          { "type": "test", "section": "âœ… Tests", "hidden": true }
        ]
      }
    }],
    ["@semantic-release/changelog", {
      "changelogFile": "CHANGELOG.md"
    }],
    ["@semantic-release/npm", {
      "npmPublish": false
    }],
    ["@semantic-release/git", {
      "assets": ["CHANGELOG.md", "package.json", "package-lock.json"],
      "message": "chore(release): ${nextRelease.version} [skip ci]\n\n${nextRelease.notes}"
    }],
    ["@semantic-release/github", {
      "assets": [
        { "path": "dist/**/*.js", "label": "Distribution" }
      ]
    }]
  ]
}
EOFSEMANTICRELEASE

echo -e "${GREEN}   âœ… .releaserc.json${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 151: .github/workflows/release.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [151/180] .github/workflows/release.yml${NC}"

cat > .github/workflows/release.yml << 'EOFRELEASEYML'
name: ğŸ·ï¸ Release

on:
  push:
    branches: [main, develop, next]

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  release:
    name: ğŸ·ï¸ Semantic Release
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build
        run: npm run build

      - name: Run Tests
        run: npm test

      - name: Semantic Release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPM_TOKEN: ${{ secrets.NPM_TOKEN }}
        run: npx semantic-release

      - name: Notify Discord
        if: success()
        run: |
          VERSION=$(node -p "require('./package.json').version")
          curl -X POST "${{ secrets.DISCORD_WEBHOOK }}" \
            -H "Content-Type: application/json" \
            -d "{\"content\": \"ğŸ‰ **Release v${VERSION}** publicada com sucesso!\\nVeja: https://github.com/${{ github.repository }}/releases\"}"
EOFRELEASEYML

echo -e "${GREEN}   âœ… .github/workflows/release.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 152: renovate.json - Dependency Management
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [152/180] renovate.json${NC}"

cat > renovate.json << 'EOFRENOVATE'
{
  "$schema": "https://docs.renovatebot.com/renovate-schema.json",
  "extends": [
    "config:recommended",
    ":dependencyDashboard",
    ":semanticCommits",
    ":separateMajorReleases",
    "group:allNonMajor"
  ],
  "timezone": "America/Sao_Paulo",
  "schedule": ["before 6am on monday"],
  "labels": ["dependencies", "automated"],
  "prHourlyLimit": 5,
  "prConcurrentLimit": 10,
  "rangeStrategy": "bump",
  "lockFileMaintenance": {
    "enabled": true,
    "schedule": ["before 6am on the first day of the month"]
  },
  "vulnerabilityAlerts": {
    "enabled": true,
    "labels": ["security"],
    "schedule": ["at any time"]
  },
  "packageRules": [
    {
      "matchPackagePatterns": ["eslint", "prettier", "@typescript-eslint"],
      "groupName": "linting tools",
      "automerge": true
    },
    {
      "matchPackagePatterns": ["jest", "vitest", "@testing-library", "playwright"],
      "groupName": "testing tools",
      "automerge": true
    },
    {
      "matchPackagePatterns": ["@types/*"],
      "groupName": "type definitions",
      "automerge": true
    },
    {
      "matchUpdateTypes": ["patch"],
      "automerge": true
    },
    {
      "matchDepTypes": ["devDependencies"],
      "matchUpdateTypes": ["minor"],
      "automerge": true
    },
    {
      "matchPackageNames": ["node"],
      "enabled": false
    },
    {
      "matchPackagePatterns": ["prisma"],
      "groupName": "prisma",
      "automerge": false
    },
    {
      "matchPackagePatterns": ["aws-sdk", "@aws-sdk"],
      "groupName": "AWS SDK",
      "schedule": ["before 6am on the first day of the month"]
    }
  ],
  "postUpdateOptions": ["npmDedupe"]
}
EOFRENOVATE

echo -e "${GREEN}   âœ… renovate.json${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 153: .github/workflows/dependency-review.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [153/180] .github/workflows/dependency-review.yml${NC}"

cat > .github/workflows/dependency-review.yml << 'EOFDEPREV'
name: ğŸ“¦ Dependency Review

on:
  pull_request:
    paths:
      - 'package.json'
      - 'package-lock.json'
      - 'yarn.lock'
      - 'pnpm-lock.yaml'

permissions:
  contents: read
  pull-requests: write

jobs:
  dependency-review:
    name: ğŸ“¦ Review Dependencies
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4

      - name: Dependency Review
        uses: actions/dependency-review-action@v3
        with:
          fail-on-severity: high
          deny-licenses: GPL-3.0, AGPL-3.0
          allow-licenses: MIT, Apache-2.0, BSD-2-Clause, BSD-3-Clause, ISC

      - name: License Check
        run: |
          npx license-checker --production --onlyAllow "MIT;Apache-2.0;BSD-2-Clause;BSD-3-Clause;ISC;0BSD;CC0-1.0;Unlicense" || echo "::warning::Some licenses need review"

      - name: Size Impact
        uses: actions/github-script@v7
        with:
          script: |
            const { execSync } = require('child_process');
            
            // Install and check bundle size
            execSync('npm ci');
            const before = execSync('du -sh node_modules').toString().trim();
            
            // Report
            const body = `## ğŸ“¦ Dependency Impact

            | Metric | Value |
            |--------|-------|
            | node_modules size | ${before} |

            _Review dependencies for security and license compliance._`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
EOFDEPREV

echo -e "${GREEN}   âœ… .github/workflows/dependency-review.yml${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVO 154: CONTRIBUTING.md atualizado
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [154/180] CONTRIBUTING.md (atualizado)${NC}"

cat > CONTRIBUTING.md << 'EOFCONTRIBUTING'
# ğŸ¤ Contributing Guide

## Quick Start

```bash
# 1. Clone
git clone https://github.com/example/app.git
cd app

# 2. Setup
./scripts/setup-all.sh

# 3. Develop
make dev
```

## Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Branch    â”‚ --> â”‚     PR      â”‚ --> â”‚   Merge     â”‚
â”‚  feature/*  â”‚     â”‚  + Preview  â”‚     â”‚   main      â”‚
â”‚   fix/*     â”‚     â”‚  + Tests    â”‚     â”‚  + Release  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Commit Convention

Usamos [Conventional Commits](https://conventionalcommits.org):

```
<type>(<scope>): <description>

[body]

[footer]
```

### Types

| Type | DescriÃ§Ã£o | Exemplo |
|------|-----------|---------|
| `feat` | Nova feature | `feat(auth): add OAuth login` |
| `fix` | Bug fix | `fix(api): handle null response` |
| `perf` | Performance | `perf(db): optimize query` |
| `refactor` | RefatoraÃ§Ã£o | `refactor: extract utils` |
| `docs` | DocumentaÃ§Ã£o | `docs: update README` |
| `test` | Testes | `test: add unit tests` |
| `chore` | ManutenÃ§Ã£o | `chore: update deps` |

### Breaking Changes

```
feat(api)!: change response format

BREAKING CHANGE: response.data is now an array
```

## Pull Request Checklist

- [ ] Branch from `develop`
- [ ] Tests passing
- [ ] Coverage maintained
- [ ] Conventional commit messages
- [ ] PR description filled
- [ ] Preview environment tested

## Code Review

| Emoji | Significado |
|-------|-------------|
| âœ… | Approved |
| ğŸ’¬ | Comment (nÃ£o bloqueia) |
| â“ | Question |
| ğŸ”§ | Request changes |
| ğŸ¨ | Style suggestion |
| ğŸš€ | Performance tip |

## Development

```bash
# Run tests
npm test

# Run E2E
npm run test:e2e

# Lint
npm run lint

# Format
npm run format

# Check all
make check
```
EOFCONTRIBUTING

echo -e "${GREEN}   âœ… CONTRIBUTING.md${NC}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ATUALIZAR QUICK_REFERENCE.md COM v8.1
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo -e "${YELLOW}   [155/180] Atualizando QUICK_REFERENCE.md${NC}"

cat >> QUICK_REFERENCE.md << 'EOFQUICKREF81'

---

## ğŸ“œ API Governance (v8.1)

```bash
# Gerar OpenAPI spec
./scripts/api/generate-openapi.sh

# Gerar com cliente TypeScript
./scripts/api/generate-openapi.sh --client

# Docs: docs/api/openapi.yaml
# Versionamento: docs/API_VERSIONING.md
```

## ğŸ”’ Security & Compliance (v8.1)

```bash
# Compliance check (LGPD, SOC2)
./scripts/security/compliance-check.sh

# Security headers check
./scripts/security/security-headers-check.sh https://app.example.com

# DAST scan (manual trigger)
gh workflow run dast.yml

# Docs: compliance/lgpd/, compliance/soc2/
```

## âš¡ Performance (v8.1)

```bash
# Lighthouse CI
npm run lighthouse

# Web Vitals check
./scripts/performance/web-vitals-check.sh https://app.example.com

# Thresholds: lighthouserc.json
```

## ğŸ”„ Migrations (v8.1)

```bash
# Zero-downtime migration
./scripts/migrations/zero-downtime-migration.sh expand
./scripts/migrations/zero-downtime-migration.sh migrate
./scripts/migrations/zero-downtime-migration.sh contract

# Docs: DISASTER_RECOVERY.md
```

## ğŸš€ Release (v8.1)

```bash
# Semantic release (automÃ¡tico em main)
npx semantic-release

# Conventional commits:
# feat: â†’ minor (1.x.0)
# fix:  â†’ patch (1.0.x)
# feat!: â†’ major (x.0.0)

# Config: .releaserc.json
```

## ğŸ”® Preview Environments (v8.1)

```bash
# AutomÃ¡tico em cada PR
# URL: https://pr-{number}.preview.example.com

# DestruÃ­do quando PR Ã© fechado
```
EOFQUICKREF81

echo -e "${GREEN}   âœ… QUICK_REFERENCE.md atualizado${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MENSAGEM FINAL v8.1 MEGA EDITION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo ""
echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}  âœ… v8.1 MEGA EDITION - INSTALADO COM SUCESSO!                              ${NC}"
echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""
echo -e "${PURPLE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   ğŸ”¥ MULTI-AGENT SYSTEM v8.1 MEGA EDITION                                    â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   A ESTRUTURA MAIS COMPLETA E ROBUSTA PARA CLAUDE CODE!                      â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   Arquivos: 180+ | Linhas: ~60.000+ | Camadas de ProteÃ§Ã£o: 30+               â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   TUDO DA v8.0 ULTIMATE +                                                    â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   ğŸ“œ API GOVERNANCE:                                                         â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… OpenAPI 3.1 spec completa                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Auto-geraÃ§Ã£o de docs e cliente TypeScript                               â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Breaking change detection no CI                                         â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… API versioning strategy documentada                                     â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   ğŸ”’ SECURITY & COMPLIANCE:                                                  â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… DAST scanning (OWASP ZAP + Nuclei)                                      â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… LGPD compliance checklist                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… SOC 2 Type II controls                                                  â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Compliance automation scripts                                           â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Security headers validation                                             â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   âš¡ PERFORMANCE & RELIABILITY:                                              â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Lighthouse CI com budgets                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Core Web Vitals monitoring                                              â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Zero-downtime database migrations                                       â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Disaster Recovery automation                                            â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… DR readiness checks                                                     â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   ğŸš€ DEVELOPER EXPERIENCE:                                                   â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Preview environments por PR                                             â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Semantic Release automÃ¡tico                                             â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Renovate (dependency management)                                        â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Dependency review com license check                                     â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… CONTRIBUTING.md completo                                                â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   ğŸ† STACK COMPLETO ENTERPRISE-GRADE                                         â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Testes: Unit + E2E + Contract + Visual + Mutation                       â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Observability: Prometheus + Grafana + SLOs                              â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… IaC: Terraform + Kubernetes + Helm                                      â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… Security: SAST + DAST + Compliance                                      â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… DevEx: Preview + Release + Dependencies                                 â•‘${NC}"
echo -e "${PURPLE}â•‘   âœ… CI/CD: 15+ workflows GitHub Actions                                     â•‘${NC}"
echo -e "${PURPLE}â•‘                                                                               â•‘${NC}"
echo -e "${PURPLE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""
echo -e "${CYAN}ğŸ“š DocumentaÃ§Ã£o Completa:${NC}"
echo -e "${WHITE}   - QUICK_REFERENCE.md         â†’ Comandos rÃ¡pidos${NC}"
echo -e "${WHITE}   - API_VERSIONING.md          â†’ EstratÃ©gia de versionamento API${NC}"
echo -e "${WHITE}   - DISASTER_RECOVERY.md       â†’ Plano de DR${NC}"
echo -e "${WHITE}   - compliance/lgpd/           â†’ LGPD checklist${NC}"
echo -e "${WHITE}   - compliance/soc2/           â†’ SOC 2 controls${NC}"
echo -e "${WHITE}   - docs/api/openapi.yaml      â†’ OpenAPI spec${NC}"
echo ""
echo -e "${YELLOW}ğŸš€ Para setup completo:${NC}"
echo -e "${WHITE}   ./scripts/setup-all.sh${NC}"
echo ""
echo -e "${GREEN}ğŸ¯ ZERO BUGS | ZERO FALHAS | COMPLIANCE GARANTIDO | PRODUÃ‡ÃƒO BLINDADA!${NC}"
echo ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARQUIVOS DE VALIDAÃ‡ÃƒO E IMPLEMENTAÃ‡ÃƒO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo -e "${YELLOW}   [156/180] scripts/validate-setup.sh${NC}"

cat > scripts/validate-setup.sh << 'EOFVALIDATESCRIPT'
#!/bin/bash
# ğŸ” VALIDATE SETUP - Verifica se a estrutura estÃ¡ 100% funcional

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m'

PASS=0; FAIL=0; WARN=0

check() {
    local name="$1"; local cmd="$2"; local critical="$3"
    if eval "$cmd" &>/dev/null; then
        echo -e "${GREEN}âœ… $name${NC}"; ((PASS++))
    elif [ "$critical" == "critical" ]; then
        echo -e "${RED}âŒ $name [CRÃTICO]${NC}"; ((FAIL++))
    else
        echo -e "${YELLOW}âš ï¸  $name${NC}"; ((WARN++))
    fi
}

echo ""
echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${CYAN}â•‘   ğŸ” VALIDAÃ‡ÃƒO DA ESTRUTURA v8.1 MEGA                         â•‘${NC}"
echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

echo -e "${CYAN}â•â•â• ESTRUTURA â•â•â•${NC}"
check "package.json" "[ -f 'package.json' ]" "critical"
check "tsconfig.json" "[ -f 'tsconfig.json' ]" "critical"
check "src/" "[ -d 'src' ]" "critical"
check "CLAUDE.md" "[ -f 'CLAUDE.md' ]"

echo ""
echo -e "${CYAN}â•â•â• GIT HOOKS â•â•â•${NC}"
check ".husky/" "[ -d '.husky' ]" "critical"
check "pre-commit" "[ -f '.husky/pre-commit' ]" "critical"
check "pre-commit executÃ¡vel" "[ -x '.husky/pre-commit' ]" "critical"
check "pre-commit tem lint" "grep -q 'lint' .husky/pre-commit" "critical"

echo ""
echo -e "${CYAN}â•â•â• CI/CD â•â•â•${NC}"
check ".github/workflows/" "[ -d '.github/workflows' ]" "critical"
WORKFLOW_COUNT=$(ls .github/workflows/*.yml 2>/dev/null | wc -l)
[ "$WORKFLOW_COUNT" -ge 3 ] && { echo -e "${GREEN}âœ… $WORKFLOW_COUNT workflows${NC}"; ((PASS++)); } || { echo -e "${YELLOW}âš ï¸  $WORKFLOW_COUNT workflows${NC}"; ((WARN++)); }

echo ""
echo -e "${CYAN}â•â•â• TESTES â•â•â•${NC}"
check "Config de teste" "[ -f 'vitest.config.ts' ] || [ -f 'jest.config.ts' ]" "critical"
check "Script test" "grep -q '\"test\"' package.json" "critical"
TEST_COUNT=$(find . -name "*.spec.ts" -o -name "*.test.ts" 2>/dev/null | grep -v node_modules | wc -l)
[ "$TEST_COUNT" -ge 1 ] && { echo -e "${GREEN}âœ… $TEST_COUNT arquivos de teste${NC}"; ((PASS++)); } || { echo -e "${YELLOW}âš ï¸  Sem testes${NC}"; ((WARN++)); }

echo ""
echo -e "${CYAN}â•â•â• LINTING â•â•â•${NC}"
check "ESLint config" "[ -f '.eslintrc.js' ] || [ -f '.eslintrc.json' ] || [ -f 'eslint.config.js' ]" "critical"
check "Script lint" "grep -q '\"lint\"' package.json" "critical"

echo ""
echo -e "${CYAN}â•â•â• DEPENDÃŠNCIAS â•â•â•${NC}"
check "Husky instalado" "grep -q '\"husky\"' package.json" "critical"
check "Framework de teste" "grep -q '\"vitest\"\|\"jest\"' package.json" "critical"

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
TOTAL=$((PASS + FAIL + WARN))
[ $TOTAL -gt 0 ] && SCORE=$((PASS * 100 / TOTAL)) || SCORE=0

if [ $FAIL -eq 0 ]; then
    echo -e "${GREEN}ğŸ‰ ESTRUTURA OPERACIONAL!${NC}"
else
    echo -e "${RED}âŒ CORRIJA OS ITENS CRÃTICOS${NC}"
fi
echo -e "ğŸ“Š ${GREEN}$PASS passou${NC} | ${RED}$FAIL falhou${NC} | ${YELLOW}$WARN alertas${NC} | Score: ${SCORE}%"
echo ""
[ $FAIL -gt 0 ] && exit 1 || exit 0
EOFVALIDATESCRIPT

chmod +x scripts/validate-setup.sh
echo -e "${GREEN}   âœ… scripts/validate-setup.sh${NC}"

echo -e "${YELLOW}   [157/180] IMPLEMENTATION_GUIDE.md${NC}"

cat > IMPLEMENTATION_GUIDE.md << 'EOFIMPLGUIDE2'
# ğŸ¯ GUIA DE IMPLEMENTAÃ‡ÃƒO DEFINITIVO

> Garante que a estrutura v8.1 funcione 100%

## CHECKLIST RÃPIDO

```bash
# 1. Executar setup
./setup-project-v8.1-MEGA.sh

# 2. Instalar deps
npm install

# 3. Validar estrutura
./scripts/validate-setup.sh

# 4. Testar hooks
git add . && git commit -m "test"  # Deve rodar lint/test
```

## O QUE DEVE ACONTECER

| AÃ§Ã£o | Resultado Esperado |
|------|-------------------|
| `git commit` | Husky roda lint + test |
| `git push` | Husky roda coverage |
| `PR criado` | CI roda automaticamente |
| `CI falha` | Merge bloqueado |
| `CI passa` | Merge liberado |

## VALIDAÃ‡ÃƒO

```bash
# Rodar validaÃ§Ã£o completa
./scripts/validate-setup.sh

# Deve mostrar:
# âœ… package.json
# âœ… .husky/
# âœ… pre-commit
# ...
# ğŸ‰ ESTRUTURA OPERACIONAL!
```

## SE ALGO FALHAR

### Hooks nÃ£o rodam
```bash
npx husky install
chmod +x .husky/*
```

### Testes falham
```bash
npm test -- --reporter verbose
```

### CI nÃ£o roda
```bash
# Verificar sintaxe
npx yaml-lint .github/workflows/*.yml
```

## MÃ‰TRICAS DE SUCESSO

- âœ… `./scripts/validate-setup.sh` passa
- âœ… `git commit` executa hooks
- âœ… CI roda em PRs
- âœ… Coverage > 80%
EOFIMPLGUIDE2

echo -e "${GREEN}   âœ… IMPLEMENTATION_GUIDE.md${NC}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ATUALIZAR setup-all.sh PARA INCLUIR VALIDAÃ‡ÃƒO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo -e "${YELLOW}   Atualizando scripts/setup-all.sh com validaÃ§Ã£o...${NC}"

cat >> scripts/setup-all.sh << 'EOFSETUPALLUPDATE'

# 8. Validar estrutura
echo -e "${YELLOW}[8/8] Validando estrutura...${NC}"
./scripts/validate-setup.sh || echo "   âš ï¸  Alguns itens precisam de atenÃ§Ã£o"

echo ""
echo -e "${GREEN}ğŸ¯ Execute './scripts/validate-setup.sh' para verificar se tudo estÃ¡ OK${NC}"
EOFSETUPALLUPDATE

